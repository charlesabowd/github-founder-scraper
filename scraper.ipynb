{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b930f8e",
   "metadata": {},
   "source": [
    "#  SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e6fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the script finishes very quickly (and generates an empty excel file), click run again\n",
    "# if the script errors on the \"Login Cell\" (added a comment to indicate which cell that is below), set IS_HEADLESS to \"False\" and run again. The scraper will automatically launch a page and attempt to login to LinkedIn. It's likely erroring because LinkedIn is asking for a captcha to verify the user is not a bot. Solve the captch/challenge and login. Once successfully logged in, set IS_HEADLESS back to \"True\" and run again.\n",
    "\n",
    "IS_HEADLESS = False\n",
    "# CHANGE THIS TO YOUR LINKEDIN ACCOUNT INFO\n",
    "LINKEDIN_EMAIL = \"XXXXXXXX\"\n",
    "LINKEDIN_PASSWORD = \"XXXXXXXXX\"\n",
    "COMPANY_CATEGORIES = {\n",
    "    \"SECURITY\": [\n",
    "        \"Okta\",\n",
    "        \"Snyk\",\n",
    "        \"R2C/Semgrep\", \n",
    "        \"Wiz\",\n",
    "        \"Lacework\",\n",
    "        \"Crowdstrike\",\n",
    "        \"Palo Alto Networks\",\n",
    "        \"Island\",\n",
    "        \"Vanta\",\n",
    "        \"Material Security\",\n",
    "        \"Abnormal Security\",\n",
    "        \"Samsara\",\n",
    "    ],\n",
    "    \"OTHER\": [\n",
    "        \"Figma\",\n",
    "        \"Airtable\",\n",
    "        \"Notion\",\n",
    "        \"Canva\",\n",
    "        \"Webflow\",\n",
    "        \"Faire\",\n",
    "        \"Deel\",\n",
    "        \"Rippling\",\n",
    "        \"Flexport\",\n",
    "        \"Benchling\",\n",
    "        \"Solugen\"\n",
    "    ],\n",
    "    \"PUBLIC\": [\n",
    "        \"Doordash\",\n",
    "        \"Uber\",\n",
    "        \"Palantir\",\n",
    "        \"Airbnb\",\n",
    "        \"Instacart\"\n",
    "    ],\n",
    "    \"INFRA\": [\n",
    "        \"Fivetran\",\n",
    "        \"DBT\",\n",
    "        \"Temporal\",\n",
    "        \"Cockroach Labs\",\n",
    "        \"Grafana\",\n",
    "        \"Zapier\",\n",
    "        \"Starburst\",\n",
    "        \"Retool\",\n",
    "        \"Sentry\",\n",
    "        \"Sourcegraph\",\n",
    "        \"Cribl\",\n",
    "        \"Vercel\",\n",
    "        \"Clickhouse\",\n",
    "        \"Github,\"\n",
    "        \"Cisco Meraki\",\n",
    "    ],\n",
    "    \"FINTECH\": [\n",
    "        \"Robinhood\",\n",
    "        \"Square\",\n",
    "        \"Stripe\",\n",
    "        \"Ramp\",\n",
    "        \"Brex\",\n",
    "        \"Plaid\",\n",
    "        \"Modern Treasury\",\n",
    "        \"Mercury\",\n",
    "        \"Persona\",\n",
    "        \"Klarna\",\n",
    "        \"Nubank\"\n",
    "    ],\n",
    "    \"CRYPTO\": [\n",
    "        \"Coinbase\",\n",
    "        \"Uniswap\",\n",
    "        \"Chainalysis\",\n",
    "        \"Arbitrum\",\n",
    "        \"TRM\",\n",
    "        \"Fireblocks\",\n",
    "        \"Eigenlayer\"\n",
    "    ],\n",
    "    \"FRONTIER\": [\n",
    "        \"Anduril\",\n",
    "        \"SpaceX\",\n",
    "        \"Zipline\",\n",
    "        \"Varda\",\n",
    "        \"Hadrian\"\n",
    "    ],\n",
    "    \"AI\": [\n",
    "        \"Bytedance\",\n",
    "        \"Scale AI\",\n",
    "        \"Anthropic\",\n",
    "        \"Robust intelligence\",\n",
    "        \"OpenAI\",\n",
    "        \"Predibase\",\n",
    "        \"Cohere\",\n",
    "        \"Databricks\",\n",
    "        \"Hugging Face\",\n",
    "        \"RunwayML\",\n",
    "        \"Tecton\",\n",
    "        \"Weights & Biases\",\n",
    "        \"Kumo AI\",\n",
    "        \"NVIDIA\",\n",
    "        \"Adept\",\n",
    "        \"Glean\",\n",
    "        \"Character.ai\",\n",
    "        \"Midjourney\",\n",
    "        \"Facebook AI\",\n",
    "        \"FAIR\",\n",
    "        \"Google brain\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063ef315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from linkedin_scraper import actions\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7957b23f",
   "metadata": {},
   "source": [
    "# LOGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3596a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error logging in. Please complete the captcha challenge and login manually.\n",
      "Message: \n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\n",
      "NoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\n",
      "dom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IF THIS CELL ERRORS DUE TO CAPTCHA, do this:\n",
    "# manually complete the captcha, click on the next cell, and select Run menu, select \"run selected cell and all below\" \n",
    "\n",
    "def instantiate_driver():\n",
    "    options = FirefoxOptions()\n",
    "    if IS_HEADLESS:\n",
    "        options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    \n",
    "    try:\n",
    "        actions.login(driver, LINKEDIN_EMAIL, LINKEDIN_PASSWORD)\n",
    "    except Exception as e:\n",
    "        print(\"Error logging in. Please complete the captcha challenge and login manually.\")\n",
    "        print(e)\n",
    "\n",
    "    time.sleep(15)\n",
    "    return driver\n",
    "    \n",
    "driver = instantiate_driver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b071f",
   "metadata": {},
   "source": [
    "# SALES NAV HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027fd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapedProfile:\n",
    "    def __init__(self, profile_name, experiences, profile_school, profile_dist, mutuals, profile_description, profile_link):\n",
    "        self.profile_name = profile_name\n",
    "        self.experiences = experiences\n",
    "        self.profile_school = profile_school\n",
    "        self.profile_dist = profile_dist\n",
    "        self.mutuals = mutuals\n",
    "        self.profile_description = profile_description\n",
    "        self.profile_link = profile_link\n",
    "\n",
    "def check_pickles(historyPickle, toScrapePickle):\n",
    "    scraped_urls = []\n",
    "    with open(historyPickle, 'rb') as f:\n",
    "        try:\n",
    "            scraped_urls = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error loading history pickle file\")\n",
    "        print(len(scraped_urls))\n",
    "\n",
    "    to_scrape_urls = []\n",
    "    with open(toScrapePickle, 'rb') as f:\n",
    "        try:\n",
    "            to_scrape_urls = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error loading to scrape url pickle file\")\n",
    "        print(len(to_scrape_urls))\n",
    "\n",
    "    return scraped_urls, to_scrape_urls\n",
    "\n",
    "def deduplicate(toScrapePickle, to_scrape_urls, already_scraped_urls):\n",
    "    to_scrape_urls = list(set(to_scrape_urls))\n",
    "    originalCount = len(to_scrape_urls)\n",
    "    to_scrape_urls = [url for url in to_scrape_urls if url not in already_scraped_urls]\n",
    "    print(f\"Removed {originalCount - len(to_scrape_urls)} duplicates\")\n",
    "\n",
    "    with open(toScrapePickle, 'wb') as to_scrape_file:\n",
    "        pickle.dump(to_scrape_urls, to_scrape_file)\n",
    "    \n",
    "    print(len(to_scrape_urls))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Wait for an element to be present on the page and return it.\n",
    "\n",
    "Parameters:\n",
    "- driver: The WebDriver instance\n",
    "- by: The method to locate the element (default: By.CLASS_NAME)\n",
    "- name: The name or identifier of the element to wait for\n",
    "- base: The base element to search from (default: None, which uses the driver)\n",
    "- timeout: Maximum time to wait for the element (default: 180 seconds)\n",
    "\n",
    "Returns:\n",
    "- The WebElement if found\n",
    "- None if the element is not found within the timeout period\n",
    "\"\"\"\n",
    "def wait_for_element_to_load(driver, by=By.CLASS_NAME, name=\"pv-top-card\", base=None, timeout=10):\n",
    "    base = base or driver\n",
    "    try:\n",
    "        element = WebDriverWait(base, timeout).until(\n",
    "            EC.presence_of_element_located((by, name))\n",
    "        )\n",
    "        return element\n",
    "    except TimeoutException:\n",
    "        print(f\"Timed out waiting for element: {by}={name}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while waiting for element {by}={name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Scrolls the page to bring the specified profile element into view\n",
    "# Returns True if successful, False if an error occurs\n",
    "def scroll_to_profile(driver, profile):\n",
    "    try:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", profile)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error scrolling to profile: {e}\")\n",
    "        return False\n",
    "\n",
    "# Clicks on the profile element to open its details\n",
    "# Returns True if successful, False if an error occurs\n",
    "def click_profile(profile):\n",
    "    try:\n",
    "        salesNavOpenProfileButton = profile.find_element(By.CLASS_NAME, \"artdeco-entity-lockup__title\")\n",
    "        salesNavOpenProfileButton.click()\n",
    "        return True\n",
    "    except (NoSuchElementException, ElementClickInterceptedException) as e:\n",
    "        print(f\"Error clicking profile: {e}\")\n",
    "        return False\n",
    "\n",
    "# Clicks the three dots button to open the dropdown menu\n",
    "# Returns True if successful, False if an error occurs\n",
    "def click_three_dots_button(driver):\n",
    "    try:\n",
    "        actionContainer = driver.find_element(By.CLASS_NAME, \"_actions-container_1dg5u8\")\n",
    "        threeDotsButton = actionContainer.find_element(By.CLASS_NAME, \"_icon_ps32ck\")\n",
    "        threeDotsButton.click()\n",
    "        return True\n",
    "    except (NoSuchElementException, ElementClickInterceptedException) as e:\n",
    "        print(f\"Error clicking three dots button\")\n",
    "        return False\n",
    "\n",
    "# Retrieves the LinkedIn URL from the dropdown menu\n",
    "# Returns the URL if successful, None if an error occurs\n",
    "def get_linkedin_url(driver):\n",
    "    try:\n",
    "        dropdownContainer = driver.find_element(By.CLASS_NAME, \"_visible_x5gf48\")\n",
    "        normalLinkedInUrl = dropdownContainer.find_elements(By.TAG_NAME, \"a\")[1].get_attribute(\"href\")\n",
    "        return normalLinkedInUrl\n",
    "    except (NoSuchElementException, IndexError) as e:\n",
    "        print(f\"Error getting LinkedIn URL: {e}\")\n",
    "        return None\n",
    "\n",
    "# Closes the profile popout\n",
    "# Returns True if successful, False if an error occurs\n",
    "def close_popout(driver):\n",
    "    try:\n",
    "        header = driver.find_element(By.CLASS_NAME, \"_inline-sidesheet-header-actions_1cn7lg\")\n",
    "        button = header.find_elements(By.CLASS_NAME, \"_button_ps32ck\")[1]\n",
    "        button.click()\n",
    "        return True\n",
    "    except (NoSuchElementException, ElementClickInterceptedException, IndexError) as e:\n",
    "        print(f\"Error closing popout: {e}\")\n",
    "        return False\n",
    "\n",
    "# Navigates to the next page of search results\n",
    "# Returns True if successful, False if there are no more pages or an error occurs\n",
    "def navigate_to_next_page(driver):\n",
    "    try:\n",
    "        nextPageButton = driver.find_element(By.CLASS_NAME, \"artdeco-pagination__button--next\")\n",
    "        nextPageButton.click()\n",
    "        return True\n",
    "    except (NoSuchElementException, ElementClickInterceptedException) as e:\n",
    "        print(f\"No more pages or error navigating: {e}\")\n",
    "        return False\n",
    "\n",
    "# Main scraping function\n",
    "def scrape_profiles(driver, SALES_NAV_SEARCH_URL, already_scraped_urls, to_scrape_urls, toScrapePickle):\n",
    "    # reinstantiate_driver(driver)\n",
    "    driver.get(SALES_NAV_SEARCH_URL)\n",
    "    \n",
    "    while True:\n",
    "        wait_for_element_to_load(driver, By.ID, \"search-results-container\")\n",
    "        profiles = driver.find_elements(By.CLASS_NAME, \"artdeco-list__item\")\n",
    "        \n",
    "        for profile in profiles:\n",
    "            if not scroll_to_profile(driver, profile):\n",
    "                continue\n",
    "\n",
    "            if not wait_for_element_to_load(driver, By.CLASS_NAME, \"artdeco-entity-lockup__title\"):\n",
    "                continue\n",
    "\n",
    "            if not click_profile(profile):\n",
    "                continue\n",
    "\n",
    "            if not wait_for_element_to_load(driver, By.CLASS_NAME, \"_actions-container_1dg5u8\"):\n",
    "                continue\n",
    "\n",
    "            # time.sleep(2 + random.random() * 6)\n",
    "\n",
    "            if not click_three_dots_button(driver):\n",
    "                continue\n",
    "\n",
    "            if not wait_for_element_to_load(driver, By.CLASS_NAME, \"_visible_x5gf48\"):\n",
    "                continue\n",
    "\n",
    "            # time.sleep(2 + random.random() * 6)\n",
    "\n",
    "            normalLinkedInUrl = get_linkedin_url(driver)\n",
    "            if normalLinkedInUrl:\n",
    "                if normalLinkedInUrl in already_scraped_urls:\n",
    "                    print(\"Skipping (already scraped): \" + normalLinkedInUrl)\n",
    "                else:\n",
    "                    to_scrape_urls.append(normalLinkedInUrl)\n",
    "                    with open(toScrapePickle, 'wb') as f:\n",
    "                        pickle.dump(to_scrape_urls, f)\n",
    "                    print(\"Successfully scraped: \" + normalLinkedInUrl)\n",
    "\n",
    "            if not close_popout(driver):\n",
    "                continue\n",
    "\n",
    "        next_button = wait_for_element_to_load(driver, By.CLASS_NAME, \"artdeco-pagination__button--next\")\n",
    "        if not next_button or not next_button.is_enabled():\n",
    "            break\n",
    "\n",
    "        next_button.click()\n",
    "\n",
    "        if not wait_for_element_to_load(driver, By.CLASS_NAME, \"artdeco-list__item\"):\n",
    "            break\n",
    "\n",
    "    return to_scrape_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c83c0",
   "metadata": {},
   "source": [
    "# PROFILE SCRAPING HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce900eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter():\n",
    "    pass     \n",
    "    # try:\n",
    "        #     WebDriverWait(driver, 240).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "        # except:\n",
    "        #     driver = reinstantiate_driver()\n",
    "\n",
    "        # # FILTERING\n",
    "        \n",
    "        # likely_founder = True\n",
    "        # relevant_exp = True\n",
    "\n",
    "        # cur_exp = experiences[0]\n",
    "        # relevant_companies = [\"stealth\", \"new\"]\n",
    "        # if any(company in cur_exp.institution_name.split(\" ·\")[0].lower() for company in relevant_companies) or \"present\" not in cur_exp.to_date.lower():\n",
    "        #     likely_founder = True\n",
    "\n",
    "        # relevant_titles = [\"product\", \"engineer\", \"sales\", \"business development\", \"founder\", \"head\", \"lead\", \"senior\", \"staff\", \"chief\", \"growth\"]\n",
    "        # for experience in experiences[1:5]:\n",
    "        #     if any(title in experience.position_title.lower() for title in relevant_titles):\n",
    "        #         relevant_exp = True\n",
    "        #         break\n",
    "        # relevant_exp = True\n",
    "\n",
    "        # if not (likely_founder and relevant_exp):\n",
    "        #     print(likely_founder, relevant_exp)\n",
    "        #     return None\n",
    "\n",
    "        # person_obj = Person(profile_link, driver = driver, scrape=False, experiences = [None])\n",
    "        # try:\n",
    "        #     WebDriverWait(driver, 240).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "        # except:\n",
    "        #     driver = reinstantiate_driver(driver)\n",
    "        # time.sleep(2 + random.random() * 7)\n",
    "        \n",
    "# Helper function to scrape experiences\n",
    "# Returns scraped experiences if successful, otherwise returns empty list\n",
    "def get_experiences(driver):\n",
    "    scraped_experiences = []\n",
    "\n",
    "    try:\n",
    "        wait_for_element_to_load(driver, By.CSS_SELECTOR, \"li.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\")\n",
    "        experience_items = driver.find_elements(By.CSS_SELECTOR, \"li.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\")\n",
    "\n",
    "        if len(experience_items) > 0:\n",
    "            print(f\"Found {len(experience_items)} experience items\")\n",
    "            for item in experience_items:\n",
    "                hidden_spans = item.find_elements(By.CSS_SELECTOR, \"span.visually-hidden\")\n",
    "                experience_texts = [span.text for span in hidden_spans]\n",
    "                experience = {\n",
    "                    \"title: \": experience_texts[0],\n",
    "                    \"company: \": experience_texts[1],\n",
    "                    \"dates: \": experience_texts[2],\n",
    "                }\n",
    "                \n",
    "                if len(experience_texts) > 3:\n",
    "                    experience[\"location: \"] = experience_texts[3]\n",
    "                if len(experience_texts) > 4:\n",
    "                    experience[\"summary: \"] = experience_texts[4]\n",
    "                if len(experience_texts) > 5:\n",
    "                    experience[\"remaining: \"] = (\", \").join(experience_texts[5:])\n",
    "\n",
    "                scraped_experiences.append(experience)\n",
    "\n",
    "            for experience in scraped_experiences:\n",
    "                for k, v in experience.items():\n",
    "                    print(f\"{k}: {v}\")\n",
    "            print(\"Successfully scraped experiences\")\n",
    "        else:\n",
    "            print(\"No experiences found\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"ERROR: No experiences found\")\n",
    "\n",
    "    return scraped_experiences\n",
    "\n",
    "\n",
    "# Helper function to scrape education\n",
    "# Returns scraped education if successful, otherwise returns empty list\n",
    "def get_education(driver):\n",
    "    scraped_education = []\n",
    "\n",
    "    try:\n",
    "        wait_for_element_to_load(driver, By.CSS_SELECTOR, \"li.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\")\n",
    "        education_items = driver.find_elements(By.CSS_SELECTOR, \"li.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\")\n",
    "\n",
    "        if len(education_items) > 0:\n",
    "            for item in education_items:\n",
    "                hidden_spans = item.find_elements(By.CSS_SELECTOR, \"span.visually-hidden\")\n",
    "                education_texts = [span.text for span in hidden_spans]\n",
    "                education = {\n",
    "                    \"school: \": education_texts[0],\n",
    "                }\n",
    "                \n",
    "                if len(education_texts) > 1:\n",
    "                    education[\"degree: \"] = education_texts[1]\n",
    "                if len(education_texts) > 2:\n",
    "                    education[\"dates: \"] = education_texts[2]\n",
    "                if len(education_texts) > 3:\n",
    "                    education[\"remaining: \"] = (\", \").join(education_texts[5:])\n",
    "\n",
    "                scraped_education.append(education)\n",
    "\n",
    "            for education in scraped_education:\n",
    "                for k, v in education.items():\n",
    "                    print(f\"{k}: {v}\")\n",
    "            print(\"Successfully scraped education\")\n",
    "        else:\n",
    "            print(\"No education found\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"ERROR: No education found\")\n",
    "\n",
    "    return scraped_education\n",
    "\n",
    "\n",
    "# Helper function to scrape degree of connection and mutuals\n",
    "# Returns scraped degree of connection and mutuals if successful, otherwise returns N/A\n",
    "def scrape_degree_of_connection_and_mutuals(driver):\n",
    "    scraped_profile_dist = \"4+\"\n",
    "    scraped_mutuals = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        scraped_profile_dist = wait_for_element_to_load(driver, By.CSS_SELECTOR, \"span.dist-value\").text\n",
    "        if scraped_profile_dist == \"1st\" or scraped_profile_dist == \"2nd\":\n",
    "            wait_for_element_to_load(driver, By.CSS_SELECTOR, \"h1.text-heading-xlarge.inline.t-24.v-align-middle.break-words\")\n",
    "            try:\n",
    "                span_element = wait_for_element_to_load(driver, By.CSS_SELECTOR, \"span.t-normal.t-black--light.t-14.hoverable-link-text\")\n",
    "                scraped_mutuals = span_element.text.split('\\n')[0]\n",
    "                print(\"Successfully found mutual connections: \" + scraped_mutuals)\n",
    "            except:\n",
    "                print(\"ERROR: mutuals not found\")\n",
    "        print(\"Successfully scraped degree of connection: \" + scraped_profile_dist)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"No degree of connection found\")\n",
    "\n",
    "    return scraped_profile_dist, scraped_mutuals\n",
    "\n",
    "# Helper function to scrape description\n",
    "# Returns scraped description if successful, otherwise returns N/A\n",
    "def scrape_description(driver):\n",
    "    scraped_description = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        scraped_description = driver.find_element(By.CLASS_NAME, \"text-body-medium.break-words\").text\n",
    "        print(\"Successfully scraped description: \" + scraped_description)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"ERROR: description not found\")\n",
    "\n",
    "\n",
    "# Main function to scrape degree of connection and mutuals\n",
    "# Returns scraped degree of connection and mutuals if successful, otherwise returns N/A\n",
    "def scrape_profile(driver, scraped_link):\n",
    "\n",
    "    # Scrape Name\n",
    "    driver.get(scraped_link)\n",
    "    scraped_profile_name = wait_for_element_to_load(driver, By.CSS_SELECTOR, \"h1.text-heading-xlarge.inline.t-24.v-align-middle.break-words\")\n",
    "\n",
    "    # Scrape Experiences\n",
    "    experiences_url = os.path.join(scraped_link, \"details/experience\")\n",
    "    print(experiences_url)\n",
    "    driver.get(experiences_url)\n",
    "    scraped_experiences = get_experiences(driver)\n",
    "    print(\"Finished scraping experiences\")\n",
    "\n",
    "    # Scrape Education\n",
    "    education_url = os.path.join(scraped_link, \"details/education\")\n",
    "    print(education_url)\n",
    "    driver.get(education_url)\n",
    "    scraped_education = get_education(driver)\n",
    "    print(\"Finished scraping education\")\n",
    "\n",
    "    # Scrape degree of connection and mutuals if available\n",
    "    driver.get(scraped_link)\n",
    "    scraped_profile_dist, scraped_mutuals = scrape_degree_of_connection_and_mutuals(driver)\n",
    "    # Scrape description\n",
    "    scraped_description = scrape_description(driver)\n",
    "\n",
    "    # Scape profile link\n",
    "    scraped_link = driver.current_url\n",
    "    print(\"Successfully scraped profile link: \" + scraped_link)\n",
    "    \n",
    "    #TODO: EDIT HERE\n",
    "    profile = ScrapedProfile(scraped_profile_name,\n",
    "                   scraped_experiences,\n",
    "                   scraped_education,\n",
    "                   scraped_profile_dist,\n",
    "                   scraped_mutuals,\n",
    "                   scraped_description,\n",
    "                   scraped_link)\n",
    "    return profile\n",
    "\n",
    "def scrape_all_profiles(driver, historyPickle, toScrapePickle, resultsPickle):\n",
    "    results = []\n",
    "    scraped_urls = []\n",
    "\n",
    "    with open(toScrapePickle, 'rb') as f:\n",
    "        try:\n",
    "            to_scrape_urls = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error loading to scrape url pickle file\")\n",
    "\n",
    "    print(f'# of profiles to scrape: {len(to_scrape_urls)}')\n",
    "    \n",
    "\n",
    "    for i in range(len(to_scrape_urls) - 1, -1, -1):\n",
    "        url = to_scrape_urls[i]\n",
    "        print(f'At index: {len(to_scrape_urls) - i} - url: {url}')\n",
    "\n",
    "        with open(historyPickle, 'rb') as f:\n",
    "            try:\n",
    "                history = pickle.load(f)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Error loading history pickle file\")\n",
    "\n",
    "        try:\n",
    "            profile = scrape_profile(driver, url)\n",
    "            if profile != None:\n",
    "                print(\"saving profile info\")\n",
    "                results.append(profile)\n",
    "\n",
    "                # TODO: I can't pickle the profile object. Find workaround like list of dict.\n",
    "                with open(resultsPickle, 'wb') as f:\n",
    "                    pickle.dump(results, f)\n",
    "                \n",
    "                print(\"adding to history\")\n",
    "                history.append(url)\n",
    "                with open(historyPickle, 'wb') as f:\n",
    "                    pickle.dump(history, f)\n",
    "                \n",
    "                print(\"recording scraped url\")\n",
    "                scraped_urls.append(url)\n",
    "            else:\n",
    "                print(\"profile filtered out\")\n",
    "            \n",
    "            print(\"removing from to-scrape\")\n",
    "            to_scrape_urls.remove(url)\n",
    "            with open(toScrapePickle, 'wb') as f:\n",
    "                pickle.dump(to_scrape_urls, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Failed to scrape profile: ', url)\n",
    "\n",
    "            # TODO: CHANGED FAILED URLS\n",
    "            with open('failed_urls.txt', 'a') as f:\n",
    "                f.write(url + '\\n')\n",
    "\n",
    "        print(((len(to_scrape_urls) - i)/len(to_scrape_urls)) * 100, '% Done - at index:', len(to_scrape_urls) - i)\n",
    "        print('\\n------------------------------------------------------------------------------------------------\\n')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b1a61-bfdb-4ec3-b5f5-8bc81d74a68d",
   "metadata": {},
   "source": [
    "# QUERY 1: MAIN COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca7a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyPickle = 'db/main_history.pickle'\n",
    "toScrapePickle = 'db/main_to_scrape.pickle'\n",
    "resultsPickle = 'db/main_results.pickle'\n",
    "\n",
    "SALES_NAV_SEARCH_URL = \"\"\"\n",
    "https://www.linkedin.com/sales/search/people#coach=false&query=(spellCorrectionEnabled%3Atrue%2CrecentSearchParam%3A(doLogHistory%3Afalse)%2Cfilters%3AList((type%3APAST_COMPANY%2Cvalues%3AList((id%3Aurn%253Ali%253Aorganization%253A1815218%2Ctext%3AUber%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A309694%2Ctext%3AAirbnb%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2857634%2Ctext%3ACoinbase%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2135371%2Ctext%3AStripe%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A20708%2Ctext%3APalantir%2520Technologies%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3608%2Ctext%3ANVIDIA%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3205573%2Ctext%3ADoorDash%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A675562%2Ctext%3ASquare%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A30846%2Ctext%3ASpaceX%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A30086%2Ctext%3APalo%2520Alto%2520Networks%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3131483%2Ctext%3AFlexport%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3477522%2Ctext%3ADatabricks%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A748731%2Ctext%3AKlarna%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3254263%2Ctext%3ARobinhood%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A6575553%2Ctext%3AByteDance%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18505670%2Ctext%3ABrex%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2732417%2Ctext%3AInstacart%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A17998520%2Ctext%3AScale%2520AI%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2684737%2Ctext%3APlaid%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3767529%2Ctext%3ANubank%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3991822%2Ctext%3AAirtable%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A10043614%2Ctext%3ASnyk%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A10607336%2Ctext%3AChainalysis%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A10893210%2Ctext%3Adbt%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11062162%2Ctext%3AGrafana%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11130470%2Ctext%3AOpenAI%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11193683%2Ctext%3AHugging%2520Face%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11247457%2Ctext%3ASolugen%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11741116%2Ctext%3ARunway%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11869260%2Ctext%3ARetool%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A1406226%2Ctext%3ARamp%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A14824547%2Ctext%3AFireblocks%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A1594050%2Ctext%3AGoogle%2520DeepMind%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A16181286%2Ctext%3AVercel%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A17932068%2Ctext%3ALacework%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A17988315%2Ctext%3ARippling%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18013280%2Ctext%3AFaire%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18293159%2Ctext%3AAnduril%2520Industries%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18309569%2Ctext%3ASemgrep%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18586257%2Ctext%3AAbnormal%2520Security%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18593641%2Ctext%3AWeights%2520%2526%2520Biases%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18742807%2Ctext%3ATRM%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18769344%2Ctext%3AModern%2520Treasury%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18777798%2Ctext%3ACribl%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18922914%2Ctext%3ADeel%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A19107985%2Ctext%3AMercury%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A24024765%2Ctext%3ACohere%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2418251%2Ctext%3AZapier%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2497653%2Ctext%3ACrowdStrike%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A27159855%2Ctext%3AStarburst%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2850862%2Ctext%3ACanva%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A30898036%2Ctext%3ANotion%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3502352%2Ctext%3AWebflow%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A35462987%2Ctext%3AVanta%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3650502%2Ctext%3AFigma%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A37564254%2Ctext%3APersona%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3769390%2Ctext%3ABenchling%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3954657%2Ctext%3AFivetran%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A40671813%2Ctext%3ARobust%2520Intelligence%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A4803356%2Ctext%3ASourcegraph%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A6424460%2Ctext%3ASentry%2520%2528sentry.io%2529%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A64890982%2Ctext%3AWiz%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A65281968%2Ctext%3ATecton%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A65638805%2Ctext%3AMaterial%2520Security%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A67081245%2Ctext%3ATemporal%2520Technologies%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A68023390%2Ctext%3AIsland%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A68047275%2Ctext%3AUniswap%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A70975817%2Ctext%3AVarda%2520Space%2520Industries%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A71668100%2Ctext%3AHadrian%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A74126343%2Ctext%3AAnthropic%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A74882602%2Ctext%3AGlean%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A7602863%2Ctext%3AZipline%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A76262108%2Ctext%3AKumo.AI%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A80114151%2Ctext%3AClickHouse%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A81330326%2Ctext%3AAdept%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A81491861%2Ctext%3APredibase%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A82318617%2Ctext%3AMidjourney%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A83019124%2Ctext%3AEigen%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A89486558%2Ctext%3ACharacter.AI%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A89962189%2Ctext%3AThe%2520Arbitrum%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A926041%2Ctext%3AOkta%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A9309408%2Ctext%3ACockroach%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A6453825%2Ctext%3ASamsara%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A92950%2Ctext%3ACisco%2520Meraki%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A101156365%2Ctext%3AManta%2520Network%2520%2528MANTA%2529%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A19104188%2Ctext%3AAvalanche%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A81901372%2Ctext%3AOptimism%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A13449964%2Ctext%3APolygon%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A72057622%2Ctext%3ASolana%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18453134%2Ctext%3ASolana%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A40769465%2Ctext%3AEthereum%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A89970028%2Ctext%3ASui%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A27137803%2Ctext%3AStarkWare%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A74341323%2Ctext%3AOsmosis%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A79119792%2Ctext%3AAptos%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A71528119%2Ctext%3ANEAR%2520Protocol%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A40708618%2Ctext%3AInjective%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A76174015%2Ctext%3AMysten%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A94854888%2Ctext%3ASei%2520Network%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A81462746%2Ctext%3ABabylonChain%2520Inc.%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A84802787%2Ctext%3AMonad%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A100996178%2Ctext%3ARitual%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A28405403%2Ctext%3ACelestia%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A82157982%2Ctext%3AAltLayer%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A75574122%2Ctext%3AFlashbots%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A69266957%2Ctext%3AAxelar%2520Network%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A80940997%2Ctext%3AAxelar%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A16181958%2Ctext%3AProtocol%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A89707979%2Ctext%3AEclipse%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A79159372%2Ctext%3AEspresso%2520Systems%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A42785598%2Ctext%3AAleo%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A86632358%2Ctext%3ALido%2520Finance%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A75654012%2Ctext%3ALayerZero%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A79296193%2Ctext%3ACompound%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18264732%2Ctext%3AdYdX%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A79948926%2Ctext%3AdYdX%2520Foundation%2CselectionType%3AINCLUDED)))%2C(type%3ALEAD_INTERACTIONS%2Cvalues%3AList((id%3ALIVP%2Ctext%3AViewed%2520profile%2CselectionType%3AEXCLUDED)%2C(id%3ALIMP%2Ctext%3AMessaged%2CselectionType%3AEXCLUDED)))%2C(type%3AFUNCTION%2Cvalues%3AList((id%3A12%2Ctext%3AHuman%2520Resources%2CselectionType%3AEXCLUDED)%2C(id%3A26%2Ctext%3ACustomer%2520Success%2520and%2520Support%2CselectionType%3AEXCLUDED)%2C(id%3A15%2Ctext%3AMarketing%2CselectionType%3AEXCLUDED)%2C(id%3A3%2Ctext%3AArts%2520and%2520Design%2CselectionType%3AEXCLUDED)%2C(id%3A1%2Ctext%3AAccounting%2CselectionType%3AEXCLUDED)%2C(id%3A2%2Ctext%3AAdministrative%2CselectionType%3AEXCLUDED)))%2C(type%3AYEARS_IN_CURRENT_POSITION%2Cvalues%3AList((id%3A1%2Ctext%3ALess%2520than%25201%2520year%2CselectionType%3AINCLUDED)))%2C(type%3APROFILE_LANGUAGE%2Cvalues%3AList((id%3Aen%2Ctext%3AEnglish%2CselectionType%3AINCLUDED))))%2Ckeywords%3A%2522something%2520new%2522%2520OR%2520%2522stealth%2522)&sessionId=stajGZpuROWIdGr%2BfkPTtA%3D%3D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93127f7e",
   "metadata": {},
   "source": [
    "### Sales nav scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0ea7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran out of input\n",
      "Error loading history pickle file\n",
      "0\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "already_scraped_urls, to_scrape_urls = check_pickles(historyPickle, toScrapePickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83345e3-d166-4e30-a7d6-2634b0db34a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Timed out waiting for element: class name=artdeco-pagination__button--next\n",
      "['https://www.linkedin.com/in/dylan-phillips-352662a1', 'https://www.linkedin.com/in/casey-kraft-6ba6028a', 'https://www.linkedin.com/in/keefer-thompson', 'https://www.linkedin.com/in/chris-a-schultz', 'https://www.linkedin.com/in/nick-catalanotto', 'https://www.linkedin.com/in/mira-hall', 'https://www.linkedin.com/in/ariannachurchill', 'https://www.linkedin.com/in/john-thomas-security', 'https://www.linkedin.com/in/laura-lamoreaux-a2a794210', 'https://www.linkedin.com/in/junbeom-chi-230050180', 'https://www.linkedin.com/in/xi-sun-161a5b54', 'https://www.linkedin.com/in/koormann', 'https://www.linkedin.com/in/anderssonrikard', 'https://www.linkedin.com/in/prasadpavuluri', 'https://www.linkedin.com/in/shelby-cundiff', 'https://www.linkedin.com/in/impradeepmondal', 'https://www.linkedin.com/in/priramachandran25', 'https://www.linkedin.com/in/wenjinglim', 'https://www.linkedin.com/in/iris-kutsyy', 'https://www.linkedin.com/in/jeffreythomascroft', 'https://www.linkedin.com/in/malikwas', 'https://www.linkedin.com/in/rickbirenbaum', 'https://www.linkedin.com/in/patrick-hogan-6753538', 'https://www.linkedin.com/in/elliotngqilin', 'https://www.linkedin.com/in/omidahourai', 'https://www.linkedin.com/in/abenegal', 'https://www.linkedin.com/in/oscar-garcia-0b49ab12a', 'https://www.linkedin.com/in/sergical', 'https://www.linkedin.com/in/marwan-moustafa-sobhy-6aa4b137', 'https://www.linkedin.com/in/rohan-hathiwala-8b24b5101', 'https://www.linkedin.com/in/quentinlintz', 'https://www.linkedin.com/in/sidray88', 'https://www.linkedin.com/in/graytowne', 'https://www.linkedin.com/in/victoriamoyeno', 'https://www.linkedin.com/in/paul-mcleod-sales', 'https://www.linkedin.com/in/lyudvig-mkrtchyan', 'https://www.linkedin.com/in/jorah-wyer-675b0b', 'https://www.linkedin.com/in/peiwang411', 'https://www.linkedin.com/in/irynacharkashyna', 'https://www.linkedin.com/in/feng-wang-71619719', 'https://www.linkedin.com/in/zachary-basu-1b335a141', 'https://www.linkedin.com/in/jamie-trainer-4200061a3', 'https://www.linkedin.com/in/eran-barak-1712652b9', 'https://www.linkedin.com/in/calum-torin-mackay', 'https://www.linkedin.com/in/noelleli', 'https://www.linkedin.com/in/terry-blessing', 'https://www.linkedin.com/in/sufyan-lattouf-46046098', 'https://www.linkedin.com/in/huntsmankyle', 'https://www.linkedin.com/in/randy-fan', 'https://www.linkedin.com/in/peter-johnson-7596aa76', 'https://www.linkedin.com/in/kelseynelson', 'https://www.linkedin.com/in/matheuscassiano', 'https://www.linkedin.com/in/kevindzkho', 'https://www.linkedin.com/in/felix-try-a53a822a4', 'https://www.linkedin.com/in/alex-morland-2a1560b0', 'https://www.linkedin.com/in/jackyyihanlu', 'https://www.linkedin.com/in/gordeev-du', 'https://www.linkedin.com/in/andrea-otero-a3b88a54', 'https://www.linkedin.com/in/curlyparadox', 'https://www.linkedin.com/in/alejandro-serrano-62b5b3283', 'https://www.linkedin.com/in/manya-chaudhary', 'https://www.linkedin.com/in/justin-brandon-03888383', 'https://www.linkedin.com/in/barton-pickett-151b0045', 'https://www.linkedin.com/in/pakther', 'https://www.linkedin.com/in/kenneth-valkenier-6a817b34', 'https://www.linkedin.com/in/asliturgut', 'https://www.linkedin.com/in/jaiminton', 'https://www.linkedin.com/in/jim-lau-1a1b43241', 'https://www.linkedin.com/in/cwesnow2000', 'https://www.linkedin.com/in/ayacobian', 'https://www.linkedin.com/in/pascalbovet', 'https://www.linkedin.com/in/mindaugasr', 'https://www.linkedin.com/in/kzhang101', 'https://www.linkedin.com/in/mikedowd729', 'https://www.linkedin.com/in/sanjeev-murthy', 'https://www.linkedin.com/in/shuai-li-599102226', 'https://www.linkedin.com/in/mehaksoni', 'https://www.linkedin.com/in/gokeojewole', 'https://www.linkedin.com/in/brian-d-twomey', 'https://www.linkedin.com/in/sidneychen', 'https://www.linkedin.com/in/ericli1234', 'https://www.linkedin.com/in/vaishali-gada-99334253', 'https://www.linkedin.com/in/pbrowning06', 'https://www.linkedin.com/in/cierra-hylton-6952451a4', 'https://www.linkedin.com/in/luke-wagner-209559271', 'https://www.linkedin.com/in/brian-dugue-aa7501182', 'https://www.linkedin.com/in/irina-gushchina-a72b2711', 'https://www.linkedin.com/in/josephinepenaga', 'https://www.linkedin.com/in/weiye-zhao-45321a287', 'https://www.linkedin.com/in/tomfburke', 'https://www.linkedin.com/in/mtn', 'https://www.linkedin.com/in/tautvydas-stukenas', 'https://www.linkedin.com/in/alan-allen-b725332a6', 'https://www.linkedin.com/in/niccolo-coluccio-49033314a', 'https://www.linkedin.com/in/phoenixmjay', 'https://www.linkedin.com/in/rodriguez-jessica', 'https://www.linkedin.com/in/brian-camacho', 'https://www.linkedin.com/in/c-mattei32', 'https://www.linkedin.com/in/md-abu-bakkr-siddik-bappi-6633471aa', 'https://www.linkedin.com/in/katielesinski', 'https://www.linkedin.com/in/brandon-renze-469285127', 'https://www.linkedin.com/in/eyal-susser-2a35112', 'https://www.linkedin.com/in/kvedula1998', 'https://www.linkedin.com/in/randall-shults', 'https://www.linkedin.com/in/jillschweitzer', 'https://www.linkedin.com/in/greghumphreys', 'https://www.linkedin.com/in/aesprice', 'https://www.linkedin.com/in/dshamany', 'https://www.linkedin.com/in/debanjan-saha-97370b195', 'https://www.linkedin.com/in/freyconnor', 'https://www.linkedin.com/in/shaonan-wang-a5457825', 'https://www.linkedin.com/in/mluksich', 'https://www.linkedin.com/in/richardyubolu', 'https://www.linkedin.com/in/jarrenreid', 'https://www.linkedin.com/in/shreyashsn', 'https://www.linkedin.com/in/felipecorreamoraes', 'https://www.linkedin.com/in/agnishbanerjee', 'https://www.linkedin.com/in/peter-ai', 'https://www.linkedin.com/in/lizhouyuan', 'https://www.linkedin.com/in/diegoholiveira', 'https://www.linkedin.com/in/kyli-k-7a1b97a5', 'https://www.linkedin.com/in/satyamsi', 'https://www.linkedin.com/in/ramalingeswara-swamy-b305b917', 'https://www.linkedin.com/in/miles-campbell-dfir', 'https://www.linkedin.com/in/williampagliaro', 'https://www.linkedin.com/in/daniemclaughlin', 'https://www.linkedin.com/in/lilla-kontra', 'https://www.linkedin.com/in/samuel-varney', 'https://www.linkedin.com/in/will-koehn-14b351144', 'https://www.linkedin.com/in/phoebeh', 'https://www.linkedin.com/in/spencer-j-jackson', 'https://www.linkedin.com/in/chris-schneider-429281191', 'https://www.linkedin.com/in/adilbukhari', 'https://www.linkedin.com/in/sushendang', 'https://www.linkedin.com/in/eugenechantk', 'https://www.linkedin.com/in/ananddtyagi', 'https://www.linkedin.com/in/matei-negulescu', 'https://www.linkedin.com/in/chellyfellow', 'https://www.linkedin.com/in/vaniatominc', 'https://www.linkedin.com/in/elizabeth-lamacchia', 'https://www.linkedin.com/in/d-riddle', 'https://www.linkedin.com/in/diego-chamorro-a4641954', 'https://www.linkedin.com/in/rosehogmire', 'https://www.linkedin.com/in/jamie-morton-0536204b', 'https://www.linkedin.com/in/barry-matsumori-35676', 'https://www.linkedin.com/in/michaeljlzhang', 'https://www.linkedin.com/in/nguyenhachuy', 'https://www.linkedin.com/in/roman-stambaugh-0815a8b2', 'https://www.linkedin.com/in/fivetentaylor', 'https://www.linkedin.com/in/guy-levi-827b92100', 'https://www.linkedin.com/in/jorden-villarreal-13091947', 'https://www.linkedin.com/in/dimitri-archatow-59935541', 'https://www.linkedin.com/in/sarah-olechowski', 'https://www.linkedin.com/in/jocelyn-beauchesne', 'https://www.linkedin.com/in/tristan-leemon', 'https://www.linkedin.com/in/mahesh-patil-7a36b5157', 'https://www.linkedin.com/in/sheilawinslow', 'https://www.linkedin.com/in/arthur-weng', 'https://www.linkedin.com/in/kenneth-b-1b2256102', 'https://www.linkedin.com/in/bleepbloopsify', 'https://www.linkedin.com/in/stacierenna', 'https://www.linkedin.com/in/tomshea', 'https://www.linkedin.com/in/shermaineheng', 'https://www.linkedin.com/in/win-sern-wong-a5409a101', 'https://www.linkedin.com/in/darrenw88', 'https://www.linkedin.com/in/eric-ransom-1471a1144', 'https://www.linkedin.com/in/luttig', 'https://www.linkedin.com/in/paalvarez', 'https://www.linkedin.com/in/nikolaicornell', 'https://www.linkedin.com/in/caio-tarnowski', 'https://www.linkedin.com/in/tommrobinson', 'https://www.linkedin.com/in/adib-ismail-721403179', 'https://www.linkedin.com/in/pei-wu-83071550', 'https://www.linkedin.com/in/markdalas', 'https://www.linkedin.com/in/andrewvincelee', 'https://www.linkedin.com/in/eli-rothschild-b922824a', 'https://www.linkedin.com/in/maanavgarg', 'https://www.linkedin.com/in/mnoblezac0219', 'https://www.linkedin.com/in/sabina-andersson-3a69015b', 'https://www.linkedin.com/in/leon-goldberg', 'https://www.linkedin.com/in/joepurull', 'https://www.linkedin.com/in/puoya', 'https://www.linkedin.com/in/ginafromme', 'https://www.linkedin.com/in/jackson-mcdaniel', 'https://www.linkedin.com/in/nitish-ratan-appanasamy-03a353a3', 'https://www.linkedin.com/in/jessicasagen', 'https://www.linkedin.com/in/sitaamalian', 'https://www.linkedin.com/in/a-patil', 'https://www.linkedin.com/in/kenneth-d-amica-90a61752', 'https://www.linkedin.com/in/nazerkan', 'https://www.linkedin.com/in/hunter-king-49736a160', 'https://www.linkedin.com/in/andr%C3%A9-mello', 'https://www.linkedin.com/in/sergeyrustamov', 'https://www.linkedin.com/in/joshuaangzhiyuan', 'https://www.linkedin.com/in/louisachoi', 'https://www.linkedin.com/in/antoinettecamastra', 'https://www.linkedin.com/in/enrica-fedeli', 'https://www.linkedin.com/in/realitycanty', 'https://www.linkedin.com/in/reed-kamsler-b0121a68', 'https://www.linkedin.com/in/martino-secchi-a73652111', 'https://www.linkedin.com/in/karttikeya-mangalam-9248a6110', 'https://www.linkedin.com/in/boliu1', 'https://www.linkedin.com/in/wahaaj-siddiqui-5b89b820', 'https://www.linkedin.com/in/sven-fors', 'https://www.linkedin.com/in/lyonbenjamin', 'https://www.linkedin.com/in/aspratte', 'https://www.linkedin.com/in/muaaz27', 'https://www.linkedin.com/in/smhaque', 'https://www.linkedin.com/in/alexjbeierly', 'https://www.linkedin.com/in/salmeenmajid', 'https://www.linkedin.com/in/pskeenan', 'https://www.linkedin.com/in/tom-elia-332660221', 'https://www.linkedin.com/in/bhabanisahu', 'https://www.linkedin.com/in/miguelmool', 'https://www.linkedin.com/in/sam-nouri-zad-061a73177', 'https://www.linkedin.com/in/karlie-ketchum-9b9b7641', 'https://www.linkedin.com/in/piyush-prahladka', 'https://www.linkedin.com/in/pfschubert', 'https://www.linkedin.com/in/jorrels', 'https://www.linkedin.com/in/ana-elisa-esparza-duarte-46978b15b', 'https://www.linkedin.com/in/jungle-jaye-826a06170', 'https://www.linkedin.com/in/acaraker', 'https://www.linkedin.com/in/marc-sun', 'https://www.linkedin.com/in/christine-habeeb-b49a238a', 'https://www.linkedin.com/in/rnelord', 'https://www.linkedin.com/in/nicolette-ng-1b5b13165', 'https://www.linkedin.com/in/ashish-bansal-19241284', 'https://www.linkedin.com/in/aseliaisakova', 'https://www.linkedin.com/in/chrisleungyt', 'https://www.linkedin.com/in/andrewj', 'https://www.linkedin.com/in/julianarombo', 'https://www.linkedin.com/in/galepedowitz', 'https://www.linkedin.com/in/lucas-xand%C3%B3-baptista-85aa701b4', 'https://www.linkedin.com/in/unicornrevops', 'https://www.linkedin.com/in/woo', 'https://www.linkedin.com/in/sebbel', 'https://www.linkedin.com/in/sagunagoel', 'https://www.linkedin.com/in/liyanaothman', 'https://www.linkedin.com/in/aleksandar-cukanovic-5bb452b3', 'https://www.linkedin.com/in/wes-w-907237169', 'https://www.linkedin.com/in/andrealachiusa', 'https://www.linkedin.com/in/connor-f-83521713b', 'https://www.linkedin.com/in/miradu', 'https://www.linkedin.com/in/monica-shen-91815014', 'https://www.linkedin.com/in/adam-alfandary', 'https://www.linkedin.com/in/ramihabal', 'https://www.linkedin.com/in/sarah-miller-b586571a1', 'https://www.linkedin.com/in/innakg', 'https://www.linkedin.com/in/justinmkwok', 'https://www.linkedin.com/in/ahmed-baig-54a37747', 'https://www.linkedin.com/in/ke-huang-07611058', 'https://www.linkedin.com/in/cody-tardy-3266a1105', 'https://www.linkedin.com/in/diogomonica', 'https://www.linkedin.com/in/remote-work-digital-nomad-patrizio-ambrosetti', 'https://www.linkedin.com/in/aditig1', 'https://www.linkedin.com/in/ben-ho-ba3277143', 'https://www.linkedin.com/in/glen-myers-8a1613', 'https://www.linkedin.com/in/brian-lin-4132737a', 'https://www.linkedin.com/in/haodu1', 'https://www.linkedin.com/in/chankeet']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    updated_to_scrape_urls = scrape_profiles(driver, SALES_NAV_SEARCH_URL, already_scraped_urls, to_scrape_urls, toScrapePickle)\n",
    "    print(updated_to_scrape_urls)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c8979-0304-4621-ae96-59108d44bada",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea0fe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicates\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "# deduplicate to_scrape_urls\n",
    "deduplicate(toScrapePickle, to_scrape_urls, already_scraped_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da7736-3078-4e03-8be6-967f48640cdc",
   "metadata": {},
   "source": [
    "### Profile scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c61b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.close()\n",
    "# driver = instantiate_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7187f14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of profiles to scrape: 260\n",
      "At index: 1 - url: https://www.linkedin.com/in/miradu\n",
      "Ran out of input\n",
      "Error loading history pickle file\n",
      "https://www.linkedin.com/in/miradu/details/experience\n",
      "Found 11 experience items\n",
      "title: : CEO & cofounder\n",
      "company: : Blaide · Full-time\n",
      "dates: : Jan 2024 to Present · 8 mos\n",
      "location: : San Francisco, California, United States · Hybrid\n",
      "summary: : Blaide is a stealth AI startup working at the intersection of climate and fintech, in service to home contractors electrifying America's 140M homes.\n",
      "title: : Vice President of Product Management\n",
      "company: : Mercury · Full-time\n",
      "dates: : Feb 2023 to Oct 2023 · 9 mos\n",
      "location: : San Francisco, California, United States · Hybrid\n",
      "summary: : As the first Vice President of Product Management at Mercury, I had the opportunity to shape the product management function for the company. Beyond developing customer obsessed innovative strategy, this involved coaching, hiring talented individuals, organizing and leading off-sites for our remote employee base, creating excellent company wide product communication, and developing processes and templates to enhance product iteration. I brought together a team of over 50 across product, data, partnerships, and operations, including hiring 8 exceptional managers and domain experts. In my role, I contributed to several key initiatives: *Facilitating alignment between product, design, and engineering leadership, fostering an environment that supports autonomous leadership and empowered our design & technical managers. *Guiding the company through the SVB crisis and playing a pivotal role in the successful launch of Mercury Vault. *Developed process and principles for new product development & acquisitions. *Streamlining the company's focus towards enhancing product velocity, prioritizing customer-centric outcomes, and eliminating non-essential tasks. *Leading the development and launch of Mercury SAFEs, which simplified the banking process for startups. *Managing a significant processor conversion, transitioning from a key external vendor to an in-house solution. *Contributing to Mercury's growth, significantly increasing both deposits and weekly signups (exact figures not disclosed here). At Mercury, our goal is to transform the startup banking experience, melding the reliability of traditional banking with innovative technology. This approach provides founders with greater control and convenience, redefining banking from a necessary task to an empowering tool for business growth.\n",
      "title: : Chime\n",
      "company: : 4 yrs 6 mos\n",
      "dates: : Director of Technical Strategy\n",
      "location: : Full-time\n",
      "summary: : Feb 2022 to Feb 2023 · 1 yr 1 mo\n",
      "remaining: : San Francisco, California, United States, Supporting the CTO and their VPs, I lead the development of Chime's technical strategy and how it enables, supports, and fosters the innovation and rapid execution across all of our product and engineering teams., Director of Product Management, Sep 2018 to Feb 2022 · 3 yrs 6 mos, San Francisco Bay Area, I started and built Chime's engineering product management team, a dozen product managers that develop our underlying financial platform (ledgers, payment gateways, ach processing, bank settlements), application services, data science, and machine learning platforms to support the creativity and needs of all Chime's engineers, product managers and designers to invent the next generation of financial products. Following Chime's acquisition of Pinch in September 2018, I bootstrapped the team and led the definition, development, iteration, public launch and scaling to >1 Million people of Chime Credit Builder and Chime's relationships with Stride Bank, Transunion, Experian, and Equifax. Credit Builder is a complete reinvention of the secured card - with no fees, 0% APR, no credit check to apply and no minimum security deposit. Furnishing payment history to all 3 bureaus, Transunion found that the average member using Credit Builder increased their credit score by 30 points, and 95% of members without a score gained one after using Credit Builder. Chime is the fastest growing bank in America, offering fee free access to your money, early access to your paycheck, up to $100 of completely free overdraft, free credit building, and a host of other features to improve your financial fitness.\n",
      "title: : CEO & cofounder\n",
      "company: : Pinch\n",
      "dates: : Apr 2016 to Sep 2018 · 2 yrs 6 mos\n",
      "location: : San Francisco Bay Area\n",
      "summary: : At pinch, we are on mission to help increase the financial stability of millennials. Through a customer driven process we built a insurance product that included lines of credit to cover at fault, but random events, a full money transmitter licensed payments stack to allow you to break up your rental payments to match your income while keeping all of the advantages of paying with a money order, and most recently, the first ever way to add your rental payment history to all 3 major credit bureaus from an app on your phone. We were featured in Lifehacker, Nerdwallet, and built a passionate organic customer-base. Many of our customers were able to increase their credit by up to 100 points, saving thousands of dollars a year on their car insurance and loan payments.\n",
      "title: : Group Product Manager\n",
      "company: : Twitter\n",
      "dates: : Nov 2011 to Apr 2016 · 4 yrs 6 mos\n",
      "location: : San Francisco Bay Area\n",
      "summary: : Led product team and strategy for Twitter, off of Twitter. Products managed by my team included Embedded Tweets&Buttons, TwitterKit, TweetDeck, and Digits (acquired by Google). Led company wide strategy for publishers: Shipped Embeddable Moments on Web and Mobile Web, and ecosystem for curation of Tweets. Led Twitter's participation in AMP. Shipped Curator, Publish, Embedded Grid, TwitterKit Native Timelines, Collections API, Tweet Composer for Apps, Digits Email in my keynote at Flight in 2015. Shipped Tweets in Google Search, visual refresh of the embedded Tweet, Collections API and embedded Timelines in Twitter SDKs. Founding Product Manager of Digits - a simple, safe way of using your phone number to sign in to your favorite apps and websites. Shipped during my keynote at Twitter's flight conference in 2014, we continue to listen to our customers and ship major updates monthly. Digits was acquired by Google as part of Fabric, and now is at the core of Firebase Phone Auth. Shipped TwitterKit, Twitter's SDK for iOS and Android for syndication of Twitter content and identity. Previously: Focused on Twitter's consumer efforts on Mobile, Web, and Tablet focused on growing Twitter through international development: Shipped a redesigned Twitter.com, affording a clean modern look and enhanced customizability to one of the world's largest websites. Shipped Twitter's emoji set, now open-sourced and available for all. Shipped Twitter for Windows 8, and Twitter for Android Tablet, embracing unique functionality to each platform. Shipped our HTML5 touch friendly tablet website, and revamped numerous parts of our iPhone/Android website increasing app downloads, improving performance, and proving out Twitter's mobile experimentation platform. Shipped modern overhaul of feature phone websites, updated our SMS partnerships, SMS fast follow, and phone number products, and built the Twitter Access mobile operator product (zero rating).\n",
      "title: : Microsoft\n",
      "company: : 2 yrs 5 mos\n",
      "dates: : Program Manager 2, Bing Mobile\n",
      "location: : Sep 2010 to Nov 2011 · 1 yr 3 mos\n",
      "summary: : • Helped bring a complete HTML5 redesign of m.bing.com and our apps to market on a wide variety of platforms; varied responsibilities included managing daily development and deployment, location features, facebook integration, mobile video search and forward looking design and platform integrations. • Aligned m.bing.com to core bing technologies for rapid deployment and measurement\n",
      "remaining: : Program Manager 2, KIN, Jul 2009 to Aug 2010 · 1 yr 2 mos, • Identified, designed, developed, deployed, and ran a solution for 10,000 live, managed, in-store retail demos of the Verizon KIN phone and its social networking features • Managed the design and development of KIN’s service backend for integrating with Facebook, Twitter, MySpace, RSS Feeds, and backing up user generated photos and video. • Designed and managed the development of KIN’s web based log search and analysis toolset.\n",
      "title: : Program Manager Intern\n",
      "company: : Microsoft\n",
      "dates: : May 2008 to Aug 2008 · 4 mos\n",
      "location: : As a program management intern on the Microsoft Office Publisher team, I rationalized our user experience for text editing, and designed the first ever easy to use consumer interfaces for OpenType font styling.\n",
      "title: : TreoCentral.com\n",
      "company: : 5 yrs 10 mos\n",
      "dates: : Editor\n",
      "location: : Sep 2005 to Jun 2008 · 2 yrs 10 mos\n",
      "summary: : •Write editorial content for the largest and oldest Palm Treo community website •Covered CTIA Wireless-Expo 2005, 2006, MacWorld 2007, San Francisco, CA; Microsoft Mobius 2005, 2006, Seattle, WA; CES 2006, 2007, Las Vegas, NV\n",
      "remaining: : Senior Editor, Sep 2002 to Sep 2005 · 3 yrs 1 mo, •Hired as a high school sophomore to write editorial content. Successfully organized reviews and contests with mobile-industry companies, managed and moderated TreoCentral forums, designed and implemented new site features, assisted users in solving problems and making informed purchase decisions, and helped build a TreoCentral user base and brand that fuels a Treo accessories store that ships more then 230,000 orders a year •Managed a staff of seven moderators and four writers •Covered CTIA 2004; San Francisco, CA, Orange Developer Conference 2005 - Sarasota, FL\n",
      "title: : Intern\n",
      "company: : Synthesis Studios\n",
      "dates: : May 2007 to Aug 2007 · 4 mos\n",
      "location: : Improved an existing Windows Mobile based social networking platform project, OneHop, by rethinking the UI and interaction model. Publicly demonstrated at Mobile Monday Boston Designed a lithium-ion battery charging circuit and board for a solar powered backpack\n",
      "title: : Design Engineer\n",
      "company: : Smartphone Experts\n",
      "dates: : May 2006 to May 2007 · 1 yr 1 mo\n",
      "location: : Run day-to-day development of dozens of unique Treo accessories. Responsible for key components at all stages of production: ideation, initial design, prototyping, working and visiting with Asian manufactures to ensure quality, packaging design, marketing, and pricing.\n",
      "title: : Contributing Writer\n",
      "company: : VisorCentral.com\n",
      "dates: : Feb 2001 to Sep 2002 · 1 yr 8 mos\n",
      "location: : •Wrote editorial content and moderated forums for the largest Handspring Visor website •Covered COMDEX 2001; Las Vegas, NV\n",
      "Successfully scraped experiences\n",
      "Finished scraping experiences\n",
      "https://www.linkedin.com/in/miradu/details/education\n",
      "school: : Franklin W. Olin College of Engineering\n",
      "degree: : BS, Electrical Engineering\n",
      "dates: : 2005 - 2009\n",
      "school: : UCL\n",
      "degree: : Economics\n",
      "dates: : 2007 - 2007\n",
      "remaining: : \n",
      "Successfully scraped education\n",
      "Finished scraping education\n",
      "Successfully found mutual connections: Ted Kornish, Lee Edwards, and 71 other mutual connections\n",
      "Successfully scraped degree of connection: 1st\n",
      "Successfully scraped description: Joyful\n",
      "successfully scraped profile link: https://www.linkedin.com/in/miradu/\n",
      "saving profile info\n",
      "Can't pickle local object '_createenviron.<locals>.encode'\n",
      "Failed to scrape profile:  https://www.linkedin.com/in/miradu\n",
      "0.38461538461538464 % Done - at index: 1\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "At index: 2 - url: https://www.linkedin.com/in/joepurull\n",
      "Ran out of input\n",
      "Error loading history pickle file\n",
      "https://www.linkedin.com/in/joepurull/details/experience\n",
      "Found 5 experience items\n",
      "title: : Systems Technician\n",
      "company: : Atom Creek, LLC · Full-time\n",
      "dates: : Jun 2024 to Present · 3 mos\n",
      "location: : Greenwood Village, Colorado, United States · On-site\n",
      "title: : Network Operations Technician I\n",
      "company: : Apex Systems (Lumen Technologies) · Contract\n",
      "dates: : May 2023 to Mar 2024 · 11 mos\n",
      "location: : Denver · Remote\n",
      "summary: : LinkedIn helped me get this job\n",
      "remaining: : • Monitored and maintained Lumen's network infrastructure, including routers, switches, servers, and data centers, to guarantee optimal performance and minimal downtime. • Performed routine system checks, diagnosed, and resolved network issues through troubleshooting, root cause analysis, and implementing effective solutions. • Actively troubleshoot various service types including Ethernet, DS1, and DS3 Circuits. • Maintained a 97% Comm Yield by providing customers with updates on the progress of their trouble report. • Monitored the performance of the telecommunications networks, including usage, load patterns and system response Qualifications using Laser – A network management tool. • Practiced Excellent Customer Service through both phone calls and electronic communication. • Demonstrated proficiency with trouble ticketing application and other internal tools., IT Support · Customer Support · Customer Retention · Internet Protocol Suite (TCP/IP) · IT Infrastructure Management · Windows Oprating Systems · Hardware and Software Configuration · Customer Service · Email Communication · Network Support · Network Troubleshooting · Computer Network Operations · Teamwork · Computer Troubleshooting · IT Operations · Network Configuration · High-Pressure Environments · Critical Thinking · Computer Networking · Troubleshooting · Remote Access · Computer Hardware Troubleshooting · Professional Phone Skills · VMware · Interpersonal Skills\n",
      "title: : Courier\n",
      "company: : DoorDash · Full-time\n",
      "dates: : Feb 2020 to Apr 2023 · 3 yrs 3 mos\n",
      "location: : Denver, Colorado, United States · On-site\n",
      "summary: : • Completed on-time deliveries by choosing the best and most efficient routes. • Communicated customer complaints, requests, and feedback to company management for swift resolution. • Updated dispatchers frequently to convey changes such as route issues or weather delays potentially impacting delivery schedules. • Contacted customers prior to delivery to confirm and coordinate delivery times. • Interacted with customers to determine needs and opportunities for additional sales. • Kept detailed records of sales, payments and completed or in-progress deliveries. • Named to the “Top Dasher” program for maintaining a completion rate above 95% and a customer rating above a 4.8/5.0\n",
      "remaining: : Communication · Customer Support · Customer Retention · Attention to Detail · Problem Solving · Customer Service · Critical Thinking · Conflict Management · Troubleshooting · Professional Phone Skills · Interpersonal Skills · Customer Experience Management\n",
      "title: : Daycare Counselor\n",
      "company: : Camp Bow Wow\n",
      "dates: : Dec 2019 to Jan 2020 · 2 mos\n",
      "location: : Denver, Colorado, United States · On-site\n",
      "summary: : • Coordinated animal training to teach commands, improve behaviors and housebreak personal pets. • Exercised animals regularly with walks and rigorous play activities. • Monitor animal behavior and identify potential illness or injury. • Kept boarding and play areas clean and sanitized to prevent illness and promote animal well-being. • Contributed to client retention by consistently providing outstanding customer service to both clients and their pets. • Worked with customers to assess quality issues, including damage and incompleteness of orders.\n",
      "remaining: : Communication · Customer Support · Customer Retention · Customer Service · Team Collaboration · Observation · Teamwork · Interpersonal Skills · Customer Experience Management\n",
      "title: : Courier Independent Contractor\n",
      "company: : Uber · Self-employed\n",
      "dates: : Sep 2018 to Dec 2019 · 1 yr 4 mos\n",
      "location: : Denver, Colorado, United States\n",
      "summary: : • Assisted passengers with entering and exiting vehicles safely and securely stowed baggage to minimize damage risk. • Achieved consistent safety targets by adjusting driving to different road and traffic conditions, balancing loads, and avoiding dangerous driving actions. • Updated personal logs and business tracking documents accurately and according to schedule requirements. • Upheld high standards of professionalism and discretion when working with customers. • Cleaned and assessed vehicle for damage after each shift to keep up with maintenance. • Coordinated efficient routes to avoid delays and optimize schedules. • Worked directly with customers to assess quality issues, including damage and incompleteness of orders.\n",
      "remaining: : Customer Support · Customer Retention · Customer Service · Professional Phone Skills · Interpersonal Skills\n",
      "Successfully scraped experiences\n",
      "Finished scraping experiences\n",
      "https://www.linkedin.com/in/joepurull/details/education\n",
      "school: : ActivateWork\n",
      "degree: : Technical Training Bootcamp, IT Support Technician\n",
      "dates: : Nov 2022 - Feb 2023\n",
      "remaining: : \n",
      "school: : University of Oklahoma\n",
      "degree: : Bachelor of Science - BS, Biology/Biological Sciences, General\n",
      "dates: : Jan 2011 - Jan 2014\n",
      "remaining: : Communication · Interpersonal Skills · Attention to Detail · Troubleshooting · Critical Thinking · Problem Solving · Conflict Management · High-Pressure Environments · Team Collaboration · Observation · Microsoft Office · Analytical Skills · Windows Oprating Systems · Teamwork · Email Communication\n",
      "school: : Willow Bend Academy\n",
      "degree: : High School Diploma, General Studies\n",
      "dates: : Aug 2005 - Feb 2009\n",
      "remaining: : \n",
      "Successfully scraped education\n",
      "Finished scraping education\n",
      "Successfully scraped degree of connection: 3rd\n",
      "Successfully scraped description: Excited to announce I am starting a new position as a Systems Technician I with Atom Creek! I am beyond excited to have this opportunity to join such an amazing team and great company.\n",
      "successfully scraped profile link: https://www.linkedin.com/in/joepurull/\n",
      "saving profile info\n",
      "Can't pickle local object '_createenviron.<locals>.encode'\n",
      "Failed to scrape profile:  https://www.linkedin.com/in/joepurull\n",
      "0.7692307692307693 % Done - at index: 2\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "At index: 3 - url: https://www.linkedin.com/in/lyudvig-mkrtchyan\n",
      "Ran out of input\n",
      "Error loading history pickle file\n",
      "https://www.linkedin.com/in/lyudvig-mkrtchyan/details/experience\n",
      "Found 9 experience items\n",
      "title: : Senior Software Engineer\n",
      "company: : Fortra · Full-time\n",
      "dates: : Jun 2024 to Present · 3 mos\n",
      "location: : Yerevan, Armenia · Hybrid\n",
      "title: : Senior Software Engineer\n",
      "company: : OneMarketData · Full-time\n",
      "dates: : Apr 2024 to Present · 5 mos\n",
      "location: : Yerevan, Armenia · Hybrid\n",
      "summary: : Spring Framework · Java\n",
      "title: : Software Engineer\n",
      "company: : Canva · Full-time\n",
      "dates: : Feb 2023 to Mar 2024 · 1 yr 2 mos\n",
      "location: : Australia\n",
      "summary: : LinkedIn helped me get this job\n",
      "remaining: : As a member of Canva's SEO growth team, I was responsible for handling SEO-related features - adding new ones and maintaining or improving existing ones. Most of the time I was working on a code base that was owned by other teams. In order to complete tasks successfully, I had to communicate with both the team that owned the code base and the stakeholders from SEO to ensure that I understood the requirements clearly. Apart from the job I was getting from SEO stakeholders, I've also created a very useful tool to automate some processes. I've noticed that a lot of small tasks my team was getting from SEO specialists had something in common. Most of the time the task was about finding all the pages with some content or component and replacing it with something else. I've developed a tool that was capable of making such changes very easily and quickly by dumping all the data from CMS and analyzing it. We have called it \"Find and Replace\" tool. I was continuously improving it and at some point even added an AI assistant. It was more like a hobby that I was doing after work or in my free time, but the F&R tool helped us a lot when we came across a migration of a large number of components to a new version (1000+ pages). It is fair to say that I'm very proud of this tool., Spring Framework · Bazel · Java · Spring Boot\n",
      "title: : Senior Software Engineer\n",
      "company: : Pure Storage · Full-time\n",
      "dates: : Apr 2022 to Nov 2022 · 8 mos\n",
      "location: : Prague, Czechia\n",
      "summary: : Project Authz: Authz is the main authorization gateway used in Pure Storage. I was a part of security team, and was responsible for adding new functionalities as well as providing support for existing once. Tech stack: - Java 11 - Spring, Spring boot - Postgres - Open Policy Agent Project New Authz: As a security team we were developing completely new version of authz from scratch. I was taking a part in requirement gathering, constructing new system design, tech stack, development of POC's and the main project. Tech stack: - Java 17 - Sping boot - Envoy - Open Policy Agent - Kubernetes - AWS - Docker\n",
      "remaining: : Spring Framework · Java · Spring Boot\n",
      "title: : Senior Software Engineer\n",
      "company: : Citrix · Full-time\n",
      "dates: : Oct 2020 to Feb 2022 · 1 yr 5 mos\n",
      "location: : Prague, Czechia\n",
      "summary: : Project Microapps ( https://docs.citrix.com/en-us/citrix-microapps.html ): Application integrations extend Citrix Workspace and their microapps provide users with a cutting-edge experience and user interface. Deliver relevant, actionable notifications, combined with intuitive microapp workflows, to make the most important use-cases of business systems and applications directly accessible from a user’s Workspace. Save users time by reducing context switching and eliminating the need to learn how to use various applications for one-off interactions. This improves the user experience because they can focus on their primary responsibilities. I've worked on different parts of project including core part, scripting-api, java deeps (bugfixes and new features), almost everything connected with backend. Technologes used: - Java 11 - Reactor Project - Spring, Spring boots - Graalvm - Microsoft sql server\n",
      "remaining: : Spring Framework · Java · Spring Boot\n",
      "title: : Senior Software Engineering\n",
      "company: : EPAM Systems · Full-time\n",
      "dates: : Nov 2018 to Oct 2020 · 2 yrs\n",
      "location: : Czech Republic\n",
      "summary: : Project Atlas Trade: Atlas Trade is a trading system of Barclays UK bank. It is a quit big project, with a lot of modules and teams working on it. I'm working on a backend part of the project. Mainly worked on monitoring and tracking mechanisms for system. Backend uses Spring framework, Aspectj, some handmade frameworks and Oracle DB with Coherence cluster. Summarize: Main technologies I've used: • Spring Framework • Oracle DB • Aspectj\n",
      "remaining: : Spring Framework · Java · Spring Boot\n",
      "title: : Senior Software Engineering\n",
      "company: : HelpSystems · Full-time\n",
      "dates: : Jun 2017 to Nov 2018 · 1 yr 6 mos\n",
      "location: : Армения\n",
      "summary: : Project Insite(https://www.helpsystems.com/products/it-operations-dashboard) HelpSystems Insite allows you to access critical information from all areas of IT—from operations to security—and empowers you to address issues in their early stages, before they impact business. I was working on back-end part of Insite itself, and related products which are integrated with it. For backend we used Spring Framework, Spring Data Jpa and Hibernate.I was the only one Java developer in our team, so all tasks related with back-end, architecture changes and some decisions, I've done myself. Summarize: Main technologies I used: • Spring Framework • Spring Data Jpa • Hibernate • PostgresSql • Aspectj\n",
      "remaining: : Spring Framework · Java · Spring Boot\n",
      "title: : Senior Software Engineer\n",
      "company: : Sberbank-Technology · Full-time\n",
      "dates: : Oct 2015 to May 2017 · 1 yr 8 mos\n",
      "location: : Moscow, Russia\n",
      "summary: : Spring Framework · Java · Spring Boot\n",
      "title: : Java Software engineer\n",
      "company: : Sourcio · Full-time\n",
      "dates: : May 2013 to Aug 2015 · 2 yrs 4 mos\n",
      "location: : Spring Framework · Java · Spring Boot\n",
      "Successfully scraped experiences\n",
      "Finished scraping experiences\n",
      "https://www.linkedin.com/in/lyudvig-mkrtchyan/details/education\n",
      "school: : Bauman Moscow State Technical University\n",
      "degree: : Master's degree, Mechatronics, Robotics, and Automation Engineering\n",
      "dates: : 2015 - 2016\n",
      "school: : State Engineering University of Armenia\n",
      "degree: : Bachelor's degree, Mechatronics, Robotics, and Automation Engineering\n",
      "dates: : 2010 - 2014\n",
      "Successfully scraped education\n",
      "Finished scraping education\n",
      "Successfully scraped degree of connection: 3rd\n",
      "Successfully scraped description: Senior Software Engineer @ Fortra | Java, Spring Framework\n",
      "successfully scraped profile link: https://www.linkedin.com/in/lyudvig-mkrtchyan/\n",
      "saving profile info\n",
      "Can't pickle local object '_createenviron.<locals>.encode'\n",
      "Failed to scrape profile:  https://www.linkedin.com/in/lyudvig-mkrtchyan\n",
      "1.153846153846154 % Done - at index: 3\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "At index: 4 - url: https://www.linkedin.com/in/daniemclaughlin\n",
      "Ran out of input\n",
      "Error loading history pickle file\n",
      "https://www.linkedin.com/in/daniemclaughlin/details/experience\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_all_profiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistoryPickle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoScrapePickle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresultsPickle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(results))\n",
      "Cell \u001b[0;32mIn[5], line 224\u001b[0m, in \u001b[0;36mscrape_all_profiles\u001b[0;34m(driver, historyPickle, toScrapePickle, resultsPickle)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading history pickle file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     profile \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_profile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving profile info\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 167\u001b[0m, in \u001b[0;36mscrape_profile\u001b[0;34m(driver, scraped_link)\u001b[0m\n\u001b[1;32m    165\u001b[0m experiences_url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(scraped_link, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetails/experience\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(experiences_url)\n\u001b[0;32m--> 167\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiences_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m scraped_experiences \u001b[38;5;241m=\u001b[39m get_experiences(driver)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished scraping experiences\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/remote/webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/remote/webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = scrape_all_profiles(driver, historyPickle, toScrapePickle, resultsPickle)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df469c1",
   "metadata": {},
   "source": [
    "# QUERY 2: UNICORN COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyPickle = 'db/unicorn_history.pickle'\n",
    "toScrapePickle = 'db/unicorn_to_scrape.pickle'\n",
    "resultsPickle = 'db/unicorn_results.pickle'\n",
    "\n",
    "SALES_NAV_SEARCH_URL = \"\"\"\n",
    "https://www.linkedin.com/sales/search/people?savedSearchId=1813072029&sessionId=yJ9IuYoZT0G8bC7kxxPinA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_sales2_search_people_saved_all%3BNTWWzarcS5mlUquty%2Fuq7A%3D%3D&snfl=uXNCEMFbT%2FSGhBJEgEzwhg%3D%3D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8a32b",
   "metadata": {},
   "source": [
    "### Sales nav scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_scraped_urls, to_scrape_urls = check_pickles(historyPickle, toScrapePickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb8467",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    updated_to_scrape_urls = scrape_profiles(driver, SALES_NAV_SEARCH_URL, already_scraped_urls, to_scrape_urls, toScrapePickle)\n",
    "    print(updated_to_scrape_urls)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff5ea6",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate to_scrape_urls\n",
    "deduplicate(toScrapePickle, to_scrape_urls, already_scraped_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8309e",
   "metadata": {},
   "source": [
    "### Profile scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = instantiate_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scrape_all_profiles(driver, historyPickle, toScrapePickle, resultsPickle)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f2e26",
   "metadata": {},
   "source": [
    "# QUERY 3: ACQUIRED COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22414fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyPickle = 'db/acquired_history.pickle'\n",
    "toScrapePickle = 'db/acquired_to_scrape.pickle'\n",
    "resultsPickle = 'db/acquired_results.pickle'\n",
    "\n",
    "SALES_NAV_SEARCH_URL = \"\"\"\n",
    "https://www.linkedin.com/sales/search/people?savedSearchId=1814608365&sessionId=yJ9IuYoZT0G8bC7kxxPinA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_sales2_search_people_saved_all%3BNTWWzarcS5mlUquty%2Fuq7A%3D%3D&snfl=cUBlHyMNTkCja4vGVma26Q%3D%3D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88db61",
   "metadata": {},
   "source": [
    "### Sales nav scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643faf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_scraped_urls, to_scrape_urls = check_pickles(historyPickle, toScrapePickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee22e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    updated_to_scrape_urls = scrape_profiles(driver, SALES_NAV_SEARCH_URL, already_scraped_urls, to_scrape_urls, toScrapePickle)\n",
    "    print(updated_to_scrape_urls)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb29f7",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d324c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate to_scrape_urls\n",
    "deduplicate(toScrapePickle, to_scrape_urls, already_scraped_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12ff51",
   "metadata": {},
   "source": [
    "### Profile scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25220f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = instantiate_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scrape_all_profiles(driver, historyPickle, toScrapePickle, resultsPickle)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b637904",
   "metadata": {},
   "source": [
    "# QUERY 4: VC PORTFOLIO COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyPickle = 'db/portfolio_history.pickle'\n",
    "toScrapePickle = 'db/portfolio_to_scrape.pickle'\n",
    "resultsPickle = 'db/portfolio_results.pickle'\n",
    "\n",
    "SALES_NAV_SEARCH_URL = \"\"\"\n",
    "https://www.linkedin.com/sales/search/people#query=(spellCorrectionEnabled%3Atrue%2CrecentSearchParam%3A(id%3A3873006364%2CdoLogHistory%3Atrue)%2Cfilters%3AList((type%3APAST_COMPANY%2Cvalues%3AList((text%3AKlaviyo%2CselectionType%3AINCLUDED)%2C(text%3ADust%2CselectionType%3AINCLUDED)%2C(text%3AEthos%2520Life%2520Agency%2CselectionType%3AINCLUDED)%2C(text%3AFactory%2CselectionType%3AINCLUDED)%2C(text%3AQuantum%2520Circuits%252C%2520Inc.%2CselectionType%3AINCLUDED)%2C(text%3AxAI%2CselectionType%3AINCLUDED)%2C(text%3ANeros%2520Technologies%2CselectionType%3AINCLUDED)%2C(text%3AAlkira%252C%2520Inc.%2CselectionType%3AINCLUDED)%2C(text%3AAPEX%2CselectionType%3AINCLUDED)%2C(text%3AStrongDM%2CselectionType%3AINCLUDED)%2C(text%3AOasis%2520Security%2CselectionType%3AINCLUDED)%2C(text%3AAnrok%2CselectionType%3AINCLUDED)%2C(text%3ACollaborative%2520Robotics%2CselectionType%3AINCLUDED)%2C(text%3AGrow%2520Therapy%2CselectionType%3AINCLUDED)%2C(text%3AZafran%2520Security%2CselectionType%3AINCLUDED)%2C(text%3AFireworks%2520AI%2CselectionType%3AINCLUDED)%2C(text%3AFoundry%2CselectionType%3AINCLUDED)%2C(text%3APhysical%2520Intelligence%2CselectionType%3AINCLUDED)%2C(text%3ARobCo%2CselectionType%3AINCLUDED)%2C(text%3AMeter%2CselectionType%3AINCLUDED)%2C(text%3APennylane%2CselectionType%3AINCLUDED)%2C(text%3AGuardant%2520Health%2CselectionType%3AINCLUDED)%2C(text%3ATacto%2CselectionType%3AINCLUDED)%2C(text%3APrivy%2CselectionType%3AINCLUDED)%2C(text%3AApollo.io%2CselectionType%3AINCLUDED)%2C(text%3ARelease%2CselectionType%3AINCLUDED)%2C(text%3ACaptions%2CselectionType%3AINCLUDED)%2C(text%3AWarp%2CselectionType%3AINCLUDED)%2C(text%3AMach%2520Industries%2CselectionType%3AINCLUDED)%2C(text%3AMedallion%2CselectionType%3AINCLUDED)%2C(text%3ADeno%2CselectionType%3AINCLUDED)%2C(text%3ACybersyn%2CselectionType%3AINCLUDED)%2C(text%3ACaldera%2CselectionType%3AINCLUDED)%2C(text%3ATavus%2CselectionType%3AINCLUDED)%2C(text%3ADagster%2520Labs%2CselectionType%3AINCLUDED)%2C(text%3ABigeye%2CselectionType%3AINCLUDED)%2C(text%3AMutiny%2CselectionType%3AINCLUDED)%2C(text%3AKnowde%2CselectionType%3AINCLUDED)%2C(text%3AStatsig%2CselectionType%3AINCLUDED)%2C(text%3APhysna%2CselectionType%3AINCLUDED)%2C(text%3AStreamlit%2CselectionType%3AINCLUDED)%2C(text%3ANeeva%2CselectionType%3AINCLUDED)%2C(text%3ALoom%2CselectionType%3AINCLUDED)%2C(text%3AAurora%2CselectionType%3AINCLUDED)%2C(text%3ATessian%2CselectionType%3AINCLUDED)%2C(text%3AAmplitude%2CselectionType%3AINCLUDED)%2C(text%3AAthelas%2CselectionType%3AINCLUDED)%2C(text%3AFilecoin%2520Labs%2CselectionType%3AINCLUDED)%2C(text%3AUnity%2CselectionType%3AINCLUDED)%2C(text%3AWhatsApp%2CselectionType%3AINCLUDED)%2C(text%3ACisco%2520Meraki%2CselectionType%3AINCLUDED)%2C(text%3ABlock%2CselectionType%3AINCLUDED)%2C(text%3ACisco%2520ThousandEyes%2CselectionType%3AINCLUDED)%2C(text%3ANimble%2520Storage%252C%2520acquired%2520by%2520Hewlett%2520Packard%2520Enterprise%2520company%2520in%25202017%2CselectionType%3AINCLUDED)%2C(text%3AFireEye%252C%2520Inc.%2CselectionType%3AINCLUDED)%2C(text%3AUpwind%2520Security%2CselectionType%3AINCLUDED)%2C(text%3AOnehouse%2CselectionType%3AINCLUDED)%2C(text%3ASeven%2520AI%2CselectionType%3AINCLUDED)%2C(text%3ABedrock%2520Security%2CselectionType%3AINCLUDED)%2C(text%3AWarpStream%2CselectionType%3AINCLUDED)%2C(text%3AKodem%2CselectionType%3AINCLUDED)%2C(text%3ABiogenesis%2CselectionType%3AINCLUDED)%2C(text%3ABraintrust%2CselectionType%3AINCLUDED)%2C(text%3AOpal%2520Security%2CselectionType%3AINCLUDED)%2C(text%3AGreenlite%2CselectionType%3AINCLUDED)%2C(text%3ACensys%2CselectionType%3AINCLUDED)%2C(text%3AApiiro%2CselectionType%3AINCLUDED)%2C(text%3ATome%2CselectionType%3AINCLUDED)%2C(text%3AStackBlitz%2CselectionType%3AINCLUDED)%2C(text%3AObsidian%2520Security%2CselectionType%3AINCLUDED)%2C(text%3AMarqeta%2CselectionType%3AINCLUDED)%2C(text%3AAppDynamics%2CselectionType%3AINCLUDED)%2C(text%3ASprig%253A%2520Eat%2520Well%2CselectionType%3AINCLUDED)%2C(text%3AOpenDNS%2CselectionType%3AINCLUDED)%2C(text%3APure%2520Storage%2CselectionType%3AINCLUDED)%2C(text%3AIBM%2520Instana%2CselectionType%3AINCL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c988d",
   "metadata": {},
   "source": [
    "### Sales nav scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3747a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_scraped_urls, to_scrape_urls = check_pickles(historyPickle, toScrapePickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    updated_to_scrape_urls = scrape_profiles(driver, SALES_NAV_SEARCH_URL, already_scraped_urls, to_scrape_urls, toScrapePickle)\n",
    "    print(updated_to_scrape_urls)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4905aa",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate to_scrape_urls\n",
    "deduplicate(toScrapePickle, to_scrape_urls, already_scraped_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5281ff8",
   "metadata": {},
   "source": [
    "### Profile scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = instantiate_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scrape_all_profiles(driver, historyPickle, toScrapePickle, resultsPickle)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d73a6f",
   "metadata": {},
   "source": [
    "# QUERY 5: INFRA COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyPickle = 'db/infra_history.pickle'\n",
    "toScrapePickle = 'db/infra_to_scrape.pickle'\n",
    "resultsPickle = 'db/infra_results.pickle'\n",
    "\n",
    "SALES_NAV_SEARCH_URL = \"\"\"\n",
    "https://www.linkedin.com/sales/search/people?savedSearchId=1813072029&sessionId=yJ9IuYoZT0G8bC7kxxPinA%3D%3D&lipi=urn%3Ali%3Apage%3Ad_sales2_search_people_saved_all%3BNTWWzarcS5mlUquty%2Fuq7A%3D%3D&snfl=uXNCEMFbT%2FSGhBJEgEzwhg%3D%3D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924aae38",
   "metadata": {},
   "source": [
    "### Sales nav scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7961266",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_scraped_urls, to_scrape_urls = check_pickles(historyPickle, toScrapePickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    updated_to_scrape_urls = scrape_profiles(driver, SALES_NAV_SEARCH_URL, already_scraped_urls, to_scrape_urls, toScrapePickle)\n",
    "    print(updated_to_scrape_urls)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8b4b3",
   "metadata": {},
   "source": [
    "### Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df023a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate to_scrape_urls\n",
    "deduplicate(toScrapePickle, to_scrape_urls, already_scraped_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55d6e65",
   "metadata": {},
   "source": [
    "### Profile scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73492e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = instantiate_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = scrape_all_profiles(driver, historyPickle, toScrapePickle, resultsPickle)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47185763-6f2b-4f89-9acc-1651887008f6",
   "metadata": {},
   "source": [
    "# EXPORTING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0906d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: FIX EXPORTS\n",
    "import pandas as pd\n",
    "\n",
    "def parseCandidate(x):\n",
    "    res = {}\n",
    "    res['url'] = x.profile_link\n",
    "    res['name'] = x.profile_name\n",
    "    res['dist'] = x.profile_dist\n",
    "    res['description'] = x.profile_description\n",
    "\n",
    "    #Experiences first\n",
    "    print(x.experiences)\n",
    "    for i, e in enumerate(x.experiences):\n",
    "        res[f'exp{i} title'] = e[\"title: \"]\n",
    "        res[f'exp{i} company'] = e[\"company: \"]\n",
    "        res[f'exp{i} dates'] = e[\"dates: \"]\n",
    "\n",
    "    # School second\n",
    "    for i, e in enumerate(x.profile_school):\n",
    "        res[f'edu{i} school'] = e[\"school: \"]\n",
    "        if \"degree :\" in e:\n",
    "            res[f'edu{i} degree'] = e[\"degree: \"]\n",
    "\n",
    "    \n",
    "    return res\n",
    "\n",
    "# New Method for Creating df\n",
    "rows = []\n",
    "for candidate in results:\n",
    "    row = parseCandidate(candidate)\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "#Export to csv\n",
    "try:\n",
    "    df.to_csv('candidates.csv', index=False)\n",
    "    print(\"Exported to csv\")\n",
    "except:\n",
    "    print(\"Failed to export to csv\")\n",
    "\n",
    "#Export to Excel\n",
    "try:\n",
    "    df.to_excel('candidates.xlsx', index=False)\n",
    "    print(\"Exported to Excel\")\n",
    "except:\n",
    "    print(\"Failed to export to Excel\")\n",
    "\n",
    "    \n",
    "# update db/already_scraped.pickle\n",
    "with open('db/already_scraped.pickle', 'rb') as f:\n",
    "    already_scraped = pickle.load(f)\n",
    "    print(f\"Previously scraped: {len(already_scraped)}\")\n",
    "    already_scraped = already_scraped + already_scraped_urls\n",
    "    already_scraped = list(set(already_scraped))\n",
    "    print(f\"Newly scraped: {len(already_scraped)}\")\n",
    "with open('db/already_scraped.pickle', 'wb') as f:\n",
    "    pickle.dump(already_scraped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97efd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "# If modifying these SCOPES, delete the file token.pickle.\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "\n",
    "def authenticate():\n",
    "    creds = None\n",
    "    # The file token.pickle stores the user's access and refresh tokens, and is created automatically when the authorization flow completes for the first time.\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'client_secrets.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    return creds\n",
    "\n",
    "def upload_file_to_drive(file_path, file_name, mime_type):\n",
    "    creds = authenticate()\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    file_metadata = {'name': file_name}\n",
    "    media = MediaFileUpload(file_path, mimetype=mime_type)\n",
    "\n",
    "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    print('File ID: %s' % file.get('id'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = 'path_to_your_local_excel_file.xlsx'  # Replace with the path to your local file\n",
    "    file_name = 'your_excel_file.xlsx'  # Replace with the desired name for the file in Google Drive\n",
    "    mime_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n",
    "\n",
    "    upload_file_to_drive(file_path, file_name, mime_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee20a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = COMPANY_CATEGORIES\n",
    "\n",
    "# Example color mapping for categories\n",
    "category_colors = {\n",
    "    \"SECURITY\": 'red',\n",
    "    \"OTHER\": 'blue',\n",
    "    \"PUBLIC\": 'green',\n",
    "    \"INFRA\": 'yellow',\n",
    "    \"FINTECH\": 'orange',\n",
    "    \"CRYPTO\": 'purple',\n",
    "    \"FRONTIER\": 'cyan',\n",
    "    \"AI\": 'magenta'\n",
    "}\n",
    "\n",
    "# Create a reverse dictionary for easier lookup: {company: category}\n",
    "company_category = {}\n",
    "for category, companies in categories.items():\n",
    "    for company in companies:\n",
    "        company_category[company] = category\n",
    "\n",
    "# Modify the style function\n",
    "def highlight_by_category(val):\n",
    "    category = company_category.get(val)\n",
    "    if category:\n",
    "        color = category_colors.get(category, 'none')  # default to 'none' if no color is specified\n",
    "    else:\n",
    "        color = 'none'\n",
    "    return f'background-color: {color}'\n",
    "\n",
    "import re\n",
    "ILLEGAL_CHARACTERS_RE = re.compile(r'[\\000-\\010]|[\\013-\\014]|[\\016-\\037]')\n",
    "def find_illegal_characters(df):\n",
    "    for column in df.columns:\n",
    "        for idx, item in enumerate(df[column]):\n",
    "            if isinstance(item, str) and ILLEGAL_CHARACTERS_RE.search(item):\n",
    "                # replace illegal characters with an empty string\n",
    "                df[column][idx] = ILLEGAL_CHARACTERS_RE.sub('', item)\n",
    "    return df\n",
    "\n",
    "styled_df = df\n",
    "styled_df = find_illegal_characters(styled_df)\n",
    "styled_df = df.style.applymap(highlight_by_category)\n",
    "\n",
    "# Save the styled DataFrame to an Excel file\n",
    "# get today's date in MM-DD-YYYY format\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%m-%d-%Y\")\n",
    "styled_df.to_excel(f'results/{date}_{start}-{end}.xlsx', engine='openpyxl', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
