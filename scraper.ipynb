{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e6fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the script finishes very quickly (and generates an empty excel file), click run again\n",
    "\n",
    "# if the script errors on the \"Login Cell\" (added a comment to indicate which cell that is below), set IS_HEADLESS to \"False\" and run again. The scraper will automatically launch a page and attempt to login to LinkedIn. It's likely erroring because LinkedIn is asking for a captcha to verify the user is not a bot. Solve the captch/challenge and login. Once successfully logged in, set IS_HEADLESS back to \"True\" and run again.\n",
    "\n",
    "IS_HEADLESS = False\n",
    "LINKEDIN_EMAIL = \"cabowd@stanford.edu\"\n",
    "LINKEDIN_PASSWORD = \"lucasanddanarecuties\"\n",
    "COMPANY_CATEGORIES = {\n",
    "    \"SECURITY\": [\n",
    "        \"Okta\",\n",
    "        \"Snyk\",\n",
    "        \"R2C/Semgrep\",\n",
    "        \"Wiz\",\n",
    "        \"Lacework\",\n",
    "        \"Crowdstrike\",\n",
    "        \"Palo Alto Networks\",\n",
    "        \"Island\",\n",
    "        \"Vanta\",\n",
    "        \"Material Security\",\n",
    "        \"Abnormal Security\",\n",
    "        \"Samsara\",\n",
    "    ],\n",
    "    \"OTHER\": [\n",
    "        \"Figma\",\n",
    "        \"Airtable\",\n",
    "        \"Notion\",\n",
    "        \"Canva\",\n",
    "        \"Webflow\",\n",
    "        \"Faire\",\n",
    "        \"Deel\",\n",
    "        \"Rippling\",\n",
    "        \"Flexport\",\n",
    "        \"Benchling\",\n",
    "        \"Solugen\"\n",
    "    ],\n",
    "    \"PUBLIC\": [\n",
    "        \"Doordash\",\n",
    "        \"Uber\",\n",
    "        \"Palantir\",\n",
    "        \"Airbnb\",\n",
    "        \"Instacart\"\n",
    "    ],\n",
    "    \"INFRA\": [\n",
    "        \"Fivetran\",\n",
    "        \"DBT\",\n",
    "        \"Temporal\",\n",
    "        \"Cockroach Labs\",\n",
    "        \"Grafana\",\n",
    "        \"Zapier\",\n",
    "        \"Starburst\",\n",
    "        \"Retool\",\n",
    "        \"Sentry\",\n",
    "        \"Sourcegraph\",\n",
    "        \"Cribl\",\n",
    "        \"Vercel\",\n",
    "        \"Clickhouse\",\n",
    "        \"Github,\"\n",
    "        \"Cisco Meraki\",\n",
    "    ],\n",
    "    \"FINTECH\": [\n",
    "        \"Robinhood\",\n",
    "        \"Square\",\n",
    "        \"Stripe\",\n",
    "        \"Ramp\",\n",
    "        \"Brex\",\n",
    "        \"Plaid\",\n",
    "        \"Modern Treasury\",\n",
    "        \"Mercury\",\n",
    "        \"Persona\",\n",
    "        \"Klarna\",\n",
    "        \"Nubank\"\n",
    "    ],\n",
    "    \"CRYPTO\": [\n",
    "        \"Coinbase\",\n",
    "        \"Uniswap\",\n",
    "        \"Chainalysis\",\n",
    "        \"Arbitrum\",\n",
    "        \"TRM\",\n",
    "        \"Fireblocks\",\n",
    "        \"Eigenlayer\"\n",
    "    ],\n",
    "    \"FRONTIER\": [\n",
    "        \"Anduril\",\n",
    "        \"SpaceX\",\n",
    "        \"Zipline\",\n",
    "        \"Varda\",\n",
    "        \"Hadrian\"\n",
    "    ],\n",
    "    \"AI\": [\n",
    "        \"Bytedance\",\n",
    "        \"Scale AI\",\n",
    "        \"Anthropic\",\n",
    "        \"Robust intelligence\",\n",
    "        \"OpenAI\",\n",
    "        \"Predibase\",\n",
    "        \"Cohere\",\n",
    "        \"Databricks\",\n",
    "        \"Hugging Face\",\n",
    "        \"RunwayML\",\n",
    "        \"Tecton\",\n",
    "        \"Weights & Biases\",\n",
    "        \"Kumo AI\",\n",
    "        \"NVIDIA\",\n",
    "        \"Adept\",\n",
    "        \"Glean\",\n",
    "        \"Character.ai\",\n",
    "        \"Midjourney\",\n",
    "        \"Facebook AI\",\n",
    "        \"FAIR\",\n",
    "        \"Google brain\"\n",
    "    ]\n",
    "}\n",
    "SALES_NAV_SEARCH_URL = \"\"\"\n",
    "https://www.linkedin.com/sales/search/people#coach=false&query=(spellCorrectionEnabled%3Atrue%2CrecentSearchParam%3A(doLogHistory%3Afalse)%2Cfilters%3AList((type%3APAST_COMPANY%2Cvalues%3AList((id%3Aurn%253Ali%253Aorganization%253A1815218%2Ctext%3AUber%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A309694%2Ctext%3AAirbnb%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2857634%2Ctext%3ACoinbase%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2135371%2Ctext%3AStripe%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A20708%2Ctext%3APalantir%2520Technologies%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3608%2Ctext%3ANVIDIA%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3205573%2Ctext%3ADoorDash%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A675562%2Ctext%3ASquare%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A30846%2Ctext%3ASpaceX%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A30086%2Ctext%3APalo%2520Alto%2520Networks%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3131483%2Ctext%3AFlexport%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3477522%2Ctext%3ADatabricks%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A748731%2Ctext%3AKlarna%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3254263%2Ctext%3ARobinhood%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A6575553%2Ctext%3AByteDance%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18505670%2Ctext%3ABrex%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2732417%2Ctext%3AInstacart%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A17998520%2Ctext%3AScale%2520AI%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2684737%2Ctext%3APlaid%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3767529%2Ctext%3ANubank%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3991822%2Ctext%3AAirtable%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A10043614%2Ctext%3ASnyk%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A10607336%2Ctext%3AChainalysis%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A10893210%2Ctext%3Adbt%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11062162%2Ctext%3AGrafana%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11130470%2Ctext%3AOpenAI%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11193683%2Ctext%3AHugging%2520Face%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11247457%2Ctext%3ASolugen%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11741116%2Ctext%3ARunway%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A11869260%2Ctext%3ARetool%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A1406226%2Ctext%3ARamp%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A14824547%2Ctext%3AFireblocks%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A1594050%2Ctext%3AGoogle%2520DeepMind%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A16181286%2Ctext%3AVercel%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A17932068%2Ctext%3ALacework%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A17988315%2Ctext%3ARippling%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18013280%2Ctext%3AFaire%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18293159%2Ctext%3AAnduril%2520Industries%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18309569%2Ctext%3ASemgrep%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18586257%2Ctext%3AAbnormal%2520Security%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18593641%2Ctext%3AWeights%2520%2526%2520Biases%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18742807%2Ctext%3ATRM%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18769344%2Ctext%3AModern%2520Treasury%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18777798%2Ctext%3ACribl%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18922914%2Ctext%3ADeel%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A19107985%2Ctext%3AMercury%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A24024765%2Ctext%3ACohere%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2418251%2Ctext%3AZapier%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2497653%2Ctext%3ACrowdStrike%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A27159855%2Ctext%3AStarburst%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A2850862%2Ctext%3ACanva%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A30898036%2Ctext%3ANotion%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3502352%2Ctext%3AWebflow%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A35462987%2Ctext%3AVanta%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3650502%2Ctext%3AFigma%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A37564254%2Ctext%3APersona%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3769390%2Ctext%3ABenchling%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A3954657%2Ctext%3AFivetran%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A40671813%2Ctext%3ARobust%2520Intelligence%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A4803356%2Ctext%3ASourcegraph%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A6424460%2Ctext%3ASentry%2520%2528sentry.io%2529%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A64890982%2Ctext%3AWiz%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A65281968%2Ctext%3ATecton%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A65638805%2Ctext%3AMaterial%2520Security%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A67081245%2Ctext%3ATemporal%2520Technologies%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A68023390%2Ctext%3AIsland%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A68047275%2Ctext%3AUniswap%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A70975817%2Ctext%3AVarda%2520Space%2520Industries%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A71668100%2Ctext%3AHadrian%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A74126343%2Ctext%3AAnthropic%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A74882602%2Ctext%3AGlean%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A7602863%2Ctext%3AZipline%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A76262108%2Ctext%3AKumo.AI%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A80114151%2Ctext%3AClickHouse%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A81330326%2Ctext%3AAdept%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A81491861%2Ctext%3APredibase%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A82318617%2Ctext%3AMidjourney%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A83019124%2Ctext%3AEigen%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A89486558%2Ctext%3ACharacter.AI%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A89962189%2Ctext%3AThe%2520Arbitrum%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A926041%2Ctext%3AOkta%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A9309408%2Ctext%3ACockroach%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A6453825%2Ctext%3ASamsara%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A92950%2Ctext%3ACisco%2520Meraki%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A101156365%2Ctext%3AManta%2520Network%2520%2528MANTA%2529%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A19104188%2Ctext%3AAvalanche%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A81901372%2Ctext%3AOptimism%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A13449964%2Ctext%3APolygon%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A72057622%2Ctext%3ASolana%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18453134%2Ctext%3ASolana%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A40769465%2Ctext%3AEthereum%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A89970028%2Ctext%3ASui%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A27137803%2Ctext%3AStarkWare%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A74341323%2Ctext%3AOsmosis%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A79119792%2Ctext%3AAptos%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A71528119%2Ctext%3ANEAR%2520Protocol%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A40708618%2Ctext%3AInjective%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A76174015%2Ctext%3AMysten%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A94854888%2Ctext%3ASei%2520Network%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A81462746%2Ctext%3ABabylonChain%2520Inc.%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A84802787%2Ctext%3AMonad%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A100996178%2Ctext%3ARitual%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A28405403%2Ctext%3ACelestia%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A82157982%2Ctext%3AAltLayer%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A75574122%2Ctext%3AFlashbots%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A69266957%2Ctext%3AAxelar%2520Network%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A80940997%2Ctext%3AAxelar%2520Foundation%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A16181958%2Ctext%3AProtocol%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A89707979%2Ctext%3AEclipse%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A79159372%2Ctext%3AEspresso%2520Systems%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A42785598%2Ctext%3AAleo%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A86632358%2Ctext%3ALido%2520Finance%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A75654012%2Ctext%3ALayerZero%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A79296193%2Ctext%3ACompound%2520Labs%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A18264732%2Ctext%3AdYdX%2CselectionType%3AINCLUDED%2Cparent%3A(id%3A0))%2C(id%3Aurn%253Ali%253Aorganization%253A79948926%2Ctext%3AdYdX%2520Foundation%2CselectionType%3AINCLUDED)))%2C(type%3ALEAD_INTERACTIONS%2Cvalues%3AList((id%3ALIVP%2Ctext%3AViewed%2520profile%2CselectionType%3AEXCLUDED)%2C(id%3ALIMP%2Ctext%3AMessaged%2CselectionType%3AEXCLUDED)))%2C(type%3AFUNCTION%2Cvalues%3AList((id%3A12%2Ctext%3AHuman%2520Resources%2CselectionType%3AEXCLUDED)%2C(id%3A26%2Ctext%3ACustomer%2520Success%2520and%2520Support%2CselectionType%3AEXCLUDED)%2C(id%3A15%2Ctext%3AMarketing%2CselectionType%3AEXCLUDED)%2C(id%3A3%2Ctext%3AArts%2520and%2520Design%2CselectionType%3AEXCLUDED)%2C(id%3A1%2Ctext%3AAccounting%2CselectionType%3AEXCLUDED)%2C(id%3A2%2Ctext%3AAdministrative%2CselectionType%3AEXCLUDED)))%2C(type%3AYEARS_IN_CURRENT_POSITION%2Cvalues%3AList((id%3A1%2Ctext%3ALess%2520than%25201%2520year%2CselectionType%3AINCLUDED)))%2C(type%3APROFILE_LANGUAGE%2Cvalues%3AList((id%3Aen%2Ctext%3AEnglish%2CselectionType%3AINCLUDED))))%2Ckeywords%3A%2522something%2520new%2522%2520OR%2520%2522stealth%2522)&sessionId=stajGZpuROWIdGr%2BfkPTtA%3D%3D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063ef315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from linkedin_scraper import actions\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c6b2b4-f89d-48aa-9547-d57915cda1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Developer/CommandLineTools/usr/bin/python3\n",
      "wagwan delilah\n"
     ]
    }
   ],
   "source": [
    "# delete this later, just checking my env\n",
    "import sys\n",
    "print(sys.executable)\n",
    "print(\"wagwan delilah\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7957b23f",
   "metadata": {},
   "source": [
    "# Login Cell Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cdabfa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\ndom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mFirefox(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# don't think this line is necessary\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#driver.get(\"https://dev.to\")\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLINKEDIN_EMAIL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLINKEDIN_PASSWORD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.linkedin.com/sales/home\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreinstantiate_driver\u001b[39m(driver):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/linkedin_scraper/actions.py:38\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(driver, email, password, cookie, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remember:\n\u001b[1;32m     36\u001b[0m         remember\u001b[38;5;241m.\u001b[39msubmit()\n\u001b[0;32m---> 38\u001b[0m element \u001b[38;5;241m=\u001b[39m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVERIFY_LOGIN_ID\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:193:5\nNoSuchElementError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:511:5\ndom.find/</<@chrome://remote/content/shared/DOM.sys.mjs:136:16\n"
     ]
    }
   ],
   "source": [
    "options = FirefoxOptions()\n",
    "if IS_HEADLESS:\n",
    "    options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(options=options)\n",
    "# don't think this line is necessary\n",
    "#driver.get(\"https://dev.to\")\n",
    "actions.login(driver, LINKEDIN_EMAIL, LINKEDIN_PASSWORD)\n",
    "driver.get(\"https://www.linkedin.com/sales/home\")\n",
    "\n",
    "def reinstantiate_driver(driver):\n",
    "    print(\"Reinstantiating driver...\")\n",
    "    options = FirefoxOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    driver.get(\"https://dev.to\")\n",
    "    actions.login(driver, LINKEDIN_EMAIL, LINKEDIN_PASSWORD)\n",
    "    driver.get(\"https://www.linkedin.com/sales/home\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314afe60-1439-4d2d-9af6-f60c08c79f5a",
   "metadata": {},
   "source": [
    "# open pickle, store already scraped urls in scraped_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43859799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('db/already_scraped.pickle', 'rb') as f:\n",
    "  scraped_urls = pickle.load(f)\n",
    "\n",
    "print(len(scraped_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bfa16f-7709-4631-858d-ab70a2e3782a",
   "metadata": {},
   "source": [
    "# Experience and ScrapedProfile classes, helper functions\n",
    "# scrape_profile_live_filtering and get_experiences functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027fd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experience():\n",
    "    position_title: str = None\n",
    "    from_date: str = None\n",
    "    to_date: str = None\n",
    "    description: str = None\n",
    "    duration: str = None\n",
    "    location: str = None\n",
    "    institution_name: str = None\n",
    "    linkedin_url: str = None\n",
    "\n",
    "class ScrapedProfile:\n",
    "    def __init__(self, profile_name, experiences, profile_school, profile_dist, profile_description, profile_link):\n",
    "        self.profile_name = profile_name\n",
    "        self.experiences = experiences\n",
    "        self.profile_school = profile_school\n",
    "        self.profile_dist = profile_dist\n",
    "        self.profile_description = profile_description\n",
    "        self.profile_link = profile_link\n",
    "\n",
    "\"\"\"\n",
    "Wait for an element to be present on the page and return it.\n",
    "\n",
    "Parameters:\n",
    "- driver: The WebDriver instance\n",
    "- by: The method to locate the element (default: By.CLASS_NAME)\n",
    "- name: The name or identifier of the element to wait for\n",
    "- base: The base element to search from (default: None, which uses the driver)\n",
    "- timeout: Maximum time to wait for the element (default: 180 seconds)\n",
    "\n",
    "Returns:\n",
    "- The WebElement if found\n",
    "- None if the element is not found within the timeout period\n",
    "\"\"\"\n",
    "def wait_for_element_to_load(driver, by=By.CLASS_NAME, name=\"pv-top-card\", base=None, timeout=180):\n",
    "    base = base or driver\n",
    "    try:\n",
    "        element = WebDriverWait(base, timeout).until(\n",
    "            EC.presence_of_element_located((by, name))\n",
    "        )\n",
    "        return element\n",
    "    except TimeoutException:\n",
    "        print(f\"Timed out waiting for element: {by}={name}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while waiting for element {by}={name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_experiences(driver):\n",
    "    driver.execute_script('alert(\"Focus window\")')\n",
    "    driver.switch_to.alert.accept()\n",
    "    try:\n",
    "        WebDriverWait(driver, 240).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "    except:\n",
    "        driver = reinstantiate_driver(driver)\n",
    "    driver.execute_script(\n",
    "                \"window.scrollTo(0, Math.ceil(document.body.scrollHeight/2));\"\n",
    "            )\n",
    "    driver.execute_script(\n",
    "                \"window.scrollTo(0, document.body.scrollHeight);\"\n",
    "            )\n",
    "    \n",
    "    experience_items = driver.find_elements(By.CSS_SELECTOR, \"li.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\")\n",
    "    print(f\"Found {len(experience_items)} experience items\")\n",
    "\n",
    "    scraped_experiences = []\n",
    "    for item in experience_items:\n",
    "        hidden_spans = item.find_elements(By.CSS_SELECTOR, \"span.visually-hidden\")\n",
    "        experience_texts = [span.text for span in hidden_spans]\n",
    "        experience = {\n",
    "            \"title: \": experience_texts[0],\n",
    "            \"company: \": experience_texts[1],\n",
    "            \"dates: \": experience_texts[2],\n",
    "        }\n",
    "        \n",
    "        if len(experience_texts) > 3:\n",
    "            experience[\"location: \"] = experience_texts[3]\n",
    "        if len(experience_texts) > 4:\n",
    "            experience[\"summary: \"] = experience_texts[4]\n",
    "        if len(experience_texts) > 5:\n",
    "            experience[\"remaining: \"] = (\", \").join(experience_texts[5:])\n",
    "\n",
    "        scraped_experiences.append(experience)\n",
    "\n",
    "    for experience in scraped_experiences:\n",
    "        for k, v in experience.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "        # experience = Experience(\n",
    "        #     position_title=position_title,\n",
    "        #     from_date=from_date,\n",
    "        #     to_date=to_date,\n",
    "        #     duration=duration,\n",
    "        #     location=location,\n",
    "        #     description=description,\n",
    "        #     institution_name=company,\n",
    "        #     linkedin_url=company_linkedin_url\n",
    "        # )\n",
    "        # experiences.append(experience)\n",
    "    return scraped_experiences\n",
    "\n",
    "def scrape_profile_live_filtering(driver, profile_link):\n",
    "\n",
    "    # Scrape Name\n",
    "    driver.get(profile_link)\n",
    "    profile_name = driver.find_element(By.CSS_SELECTOR, \"div.artdeco-entity-lockup__title.ember-view\")\n",
    "    time.sleep(1 + random.random())\n",
    "\n",
    "    # Scrape Experiences\n",
    "    experiences_url = os.path.join(profile_link, \"details/experience\")\n",
    "    print(experiences_url)\n",
    "    driver.get(experiences_url)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 240).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "    except:\n",
    "        driver = reinstantiate_driver(driver)\n",
    "    time.sleep(5 + random.random() * 10)\n",
    "    experiences = get_experiences(driver)\n",
    "    \n",
    "    print(\"Successfully scraped experiences\")\n",
    "\n",
    "    \n",
    "    # # FILTERING\n",
    "    # likely_founder = True\n",
    "    # relevant_exp = True\n",
    "\n",
    "    # cur_exp = experiences[0]\n",
    "    # relevant_companies = [\"stealth\", \"new\"]\n",
    "    # if any(company in cur_exp.institution_name.split(\" Â·\")[0].lower() for company in relevant_companies) or \"present\" not in cur_exp.to_date.lower():\n",
    "    #     likely_founder = True\n",
    "\n",
    "    # relevant_titles = [\"product\", \"engineer\", \"sales\", \"business development\", \"founder\", \"head\", \"lead\", \"senior\", \"staff\", \"chief\", \"growth\"]\n",
    "    # for experience in experiences[1:5]:\n",
    "    #     if any(title in experience.position_title.lower() for title in relevant_titles):\n",
    "    #         relevant_exp = True\n",
    "    #         break\n",
    "    # relevant_exp = True\n",
    "\n",
    "    # if not (likely_founder and relevant_exp):\n",
    "    #     print(likely_founder, relevant_exp)\n",
    "    #     return None\n",
    "\n",
    "    # person_obj = Person(profile_link, driver = driver, scrape=False, experiences = [None])\n",
    "    # try:\n",
    "    #     WebDriverWait(driver, 240).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "    # except:\n",
    "    #     driver = reinstantiate_driver(driver)\n",
    "    # time.sleep(2 + random.random() * 7)\n",
    "\n",
    "\n",
    "    # Scrape Education\n",
    "    try:\n",
    "        education_url = os.path.join(profile_link, \"details/education\")\n",
    "        driver.get(education_url)\n",
    "        \n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"li.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\")))\n",
    "        education_items = driver.find_elements(By.CSS_SELECTOR, \"li.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\")\n",
    "\n",
    "        scraped_education = []\n",
    "        if len(education_items) > 0:\n",
    "            for item in education_items:\n",
    "                hidden_spans = item.find_elements(By.CSS_SELECTOR, \"span.visually-hidden\")\n",
    "                education_texts = [span.text for span in hidden_spans]\n",
    "                education = {\n",
    "                    \"school: \": education_texts[0],\n",
    "                }\n",
    "                \n",
    "                if len(education_texts) > 1:\n",
    "                    education[\"degree: \"] = education_texts[1]\n",
    "                if len(education_texts) > 2:\n",
    "                    education[\"dates: \"] = education_texts[2]\n",
    "                if len(education_texts) > 3:\n",
    "                    education[\"remaining: \"] = (\", \").join(education_texts[5:])\n",
    "\n",
    "                scraped_education.append(education)\n",
    "\n",
    "            time.sleep(1 + random.random())\n",
    "            for education in scraped_education:\n",
    "                for k, v in education.items():\n",
    "                    print(f\"{k}: {v}\")\n",
    "        else:\n",
    "            print(\"No education found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"education not found\")\n",
    "\n",
    "    print(\"successfully scraped education\")\n",
    "\n",
    "    # Scrape degree of connection\n",
    "    driver.get(profile_link)\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"span.dist-value\")))\n",
    "        profile_dist = driver.find_element(By.CLASS_NAME, \"dist-value\").text\n",
    "        print(\"successfully scraped degree of connection\")\n",
    "    except:\n",
    "        profile_dist = \"N/A\"\n",
    "        print(\"degree of connection not found\")\n",
    "\n",
    "    # Scrape description\n",
    "    try:\n",
    "        profile_description = driver.find_element(By.CLASS_NAME, \"text-body-medium.break-words\").text\n",
    "        print(\"successfully scraped description\")\n",
    "    except:\n",
    "        profile_description = \"N/A\"\n",
    "        print(\"description not found\")\n",
    "\n",
    "    # Scape profile link\n",
    "    profile_link = driver.current_url\n",
    "    time.sleep(1 + random.random())\n",
    "    print(\"successfully scraped profile link\")\n",
    "    \n",
    "    profile = ScrapedProfile(profile_name,\n",
    "                   experiences,\n",
    "                   scraped_education,\n",
    "                   profile_dist,\n",
    "                   profile_description,\n",
    "                   profile_link)\n",
    "    print(profile)\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b1a61-bfdb-4ec3-b5f5-8bc81d74a68d",
   "metadata": {},
   "source": [
    "# load to_scrape_urls from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0ea7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "with open('db/to_scrape.pickle', 'rb') as f:\n",
    "  to_scrape_urls = pickle.load(f)\n",
    "print(len(to_scrape_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0aa233-bd14-4eae-82a8-8896bf23414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "print(len(to_scrape_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3118f-25a6-4de7-936d-5e009afdb22d",
   "metadata": {},
   "source": [
    "# SALES NAV PAGE SCRAPER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83345e3-d166-4e30-a7d6-2634b0db34a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n",
      "Error clicking three dots button\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 131\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m to_scrape_urls\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     updated_to_scrape_urls \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_profiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSALES_NAV_SEARCH_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscraped_urls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_scrape_urls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mprint\u001b[39m(updated_to_scrape_urls)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[9], line 95\u001b[0m, in \u001b[0;36mscrape_profiles\u001b[0;34m(driver, SALES_NAV_SEARCH_URL, scraped_urls, to_scrape_urls)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wait_for_element_to_load(driver, By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_actions-container_1dg5u8\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m click_three_dots_button(driver):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rebuilding old\n",
    "\n",
    "# Scrolls the page to bring the specified profile element into view\n",
    "# Returns True if successful, False if an error occurs\n",
    "def scroll_to_profile(driver, profile):\n",
    "    try:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", profile)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error scrolling to profile: {e}\")\n",
    "        return False\n",
    "\n",
    "# Clicks on the profile element to open its details\n",
    "# Returns True if successful, False if an error occurs\n",
    "def click_profile(profile):\n",
    "    try:\n",
    "        salesNavOpenProfileButton = profile.find_element(By.CLASS_NAME, \"artdeco-entity-lockup__title\")\n",
    "        salesNavOpenProfileButton.click()\n",
    "        return True\n",
    "    except (NoSuchElementException, ElementClickInterceptedException) as e:\n",
    "        print(f\"Error clicking profile: {e}\")\n",
    "        return False\n",
    "\n",
    "# Clicks the three dots button to open the dropdown menu\n",
    "# Returns True if successful, False if an error occurs\n",
    "def click_three_dots_button(driver):\n",
    "    try:\n",
    "        actionContainer = driver.find_element(By.CLASS_NAME, \"_actions-container_1dg5u8\")\n",
    "        threeDotsButton = actionContainer.find_element(By.CLASS_NAME, \"_icon_ps32ck\")\n",
    "        threeDotsButton.click()\n",
    "        return True\n",
    "    except (NoSuchElementException, ElementClickInterceptedException) as e:\n",
    "        print(f\"Error clicking three dots button\")\n",
    "        return False\n",
    "\n",
    "# Retrieves the LinkedIn URL from the dropdown menu\n",
    "# Returns the URL if successful, None if an error occurs\n",
    "def get_linkedin_url(driver):\n",
    "    try:\n",
    "        dropdownContainer = driver.find_element(By.CLASS_NAME, \"_visible_x5gf48\")\n",
    "        normalLinkedInUrl = dropdownContainer.find_elements(By.TAG_NAME, \"a\")[1].get_attribute(\"href\")\n",
    "        return normalLinkedInUrl\n",
    "    except (NoSuchElementException, IndexError) as e:\n",
    "        print(f\"Error getting LinkedIn URL: {e}\")\n",
    "        return None\n",
    "\n",
    "# Closes the profile popout\n",
    "# Returns True if successful, False if an error occurs\n",
    "def close_popout(driver):\n",
    "    try:\n",
    "        header = driver.find_element(By.CLASS_NAME, \"_inline-sidesheet-header-actions_1cn7lg\")\n",
    "        button = header.find_elements(By.CLASS_NAME, \"_button_ps32ck\")[1]\n",
    "        button.click()\n",
    "        return True\n",
    "    except (NoSuchElementException, ElementClickInterceptedException, IndexError) as e:\n",
    "        print(f\"Error closing popout: {e}\")\n",
    "        return False\n",
    "\n",
    "# Navigates to the next page of search results\n",
    "# Returns True if successful, False if there are no more pages or an error occurs\n",
    "def navigate_to_next_page(driver):\n",
    "    try:\n",
    "        nextPageButton = driver.find_element(By.CLASS_NAME, \"artdeco-pagination__button--next\")\n",
    "        nextPageButton.click()\n",
    "        return True\n",
    "    except (NoSuchElementException, ElementClickInterceptedException) as e:\n",
    "        print(f\"No more pages or error navigating: {e}\")\n",
    "        return False\n",
    "\n",
    "# Main scraping function\n",
    "def scrape_profiles(driver, SALES_NAV_SEARCH_URL, scraped_urls, to_scrape_urls):\n",
    "    driver.get(SALES_NAV_SEARCH_URL)\n",
    "    if not wait_for_element_to_load(driver, By.TAG_NAME, \"body\", timeout=240):\n",
    "        print(\"Timeout waiting for page to load\")\n",
    "        return to_scrape_urls\n",
    "\n",
    "    time.sleep(2 + random.random() * 6)\n",
    "    \n",
    "    while True:\n",
    "        profiles = driver.find_elements(By.CLASS_NAME, \"artdeco-list__item\")\n",
    "        \n",
    "        for profile in profiles:\n",
    "            if not scroll_to_profile(driver, profile):\n",
    "                continue\n",
    "\n",
    "            if not wait_for_element_to_load(driver, By.CLASS_NAME, \"artdeco-entity-lockup__title\"):\n",
    "                continue\n",
    "\n",
    "            if not click_profile(profile):\n",
    "                continue\n",
    "\n",
    "            if not wait_for_element_to_load(driver, By.CLASS_NAME, \"_actions-container_1dg5u8\"):\n",
    "                continue\n",
    "\n",
    "            time.sleep(2 + random.random() * 6)\n",
    "\n",
    "            if not click_three_dots_button(driver):\n",
    "                continue\n",
    "\n",
    "            if not wait_for_element_to_load(driver, By.CLASS_NAME, \"_visible_x5gf48\"):\n",
    "                continue\n",
    "\n",
    "            time.sleep(2 + random.random() * 6)\n",
    "\n",
    "            normalLinkedInUrl = get_linkedin_url(driver)\n",
    "            if normalLinkedInUrl:\n",
    "                if normalLinkedInUrl in scraped_urls:\n",
    "                    print(f\"Skipping (already scraped) {normalLinkedInUrl}\")\n",
    "                else:\n",
    "                    to_scrape_urls.append(normalLinkedInUrl)\n",
    "                    with open('db/to_scrape.pickle', 'wb') as f:\n",
    "                        pickle.dump(to_scrape_urls, f)\n",
    "                    print(normalLinkedInUrl)\n",
    "\n",
    "            if not close_popout(driver):\n",
    "                continue\n",
    "\n",
    "        next_button = wait_for_element_to_load(driver, By.CLASS_NAME, \"artdeco-pagination__button--next\")\n",
    "        if not next_button or not next_button.is_enabled():\n",
    "            break\n",
    "\n",
    "        next_button.click()\n",
    "\n",
    "        if not wait_for_element_to_load(driver, By.CLASS_NAME, \"artdeco-list__item\"):\n",
    "            break\n",
    "\n",
    "        time.sleep(2 + random.random() * 6)\n",
    "\n",
    "    return to_scrape_urls\n",
    "try:\n",
    "    updated_to_scrape_urls = scrape_profiles(driver, SALES_NAV_SEARCH_URL, scraped_urls, to_scrape_urls)\n",
    "    print(updated_to_scrape_urls)\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d4f0599-f3d3-4423-9088-15da03a7dc52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.linkedin.com/in/westonbell-geddes', 'https://www.linkedin.com/in/jeffwinner', 'https://www.linkedin.com/in/lucreziacanevari', 'https://www.linkedin.com/in/nbnassiri', 'https://www.linkedin.com/in/samlauj', 'https://www.linkedin.com/in/hkimia', 'https://www.linkedin.com/in/aquinorodrigo', 'https://www.linkedin.com/in/miakovenko', 'https://www.linkedin.com/in/edwardjhu', 'https://www.linkedin.com/in/nicolekjiang', 'https://www.linkedin.com/in/gal-ron', 'https://www.linkedin.com/in/justquan', 'https://www.linkedin.com/in/ying-zhu-763a3879', 'https://www.linkedin.com/in/ctle', 'https://www.linkedin.com/in/yazwashere', 'https://www.linkedin.com/in/pennypinyichen', 'https://www.linkedin.com/in/amirmehler', 'https://www.linkedin.com/in/bland-jacob', 'https://www.linkedin.com/in/tarun-firodiya', 'https://www.linkedin.com/in/eladbr', 'https://www.linkedin.com/in/alexander-mezhirov-348a02141', 'https://www.linkedin.com/in/yehonatan-steinmetz-6424859', 'https://www.linkedin.com/in/mosegaard', 'https://www.linkedin.com/in/przemekbober', 'https://www.linkedin.com/in/mrmingjiang', 'https://www.linkedin.com/in/tilakrajt', 'https://www.linkedin.com/in/laugri', 'https://www.linkedin.com/in/jajoosagar', 'https://www.linkedin.com/in/kateyeh', 'https://www.linkedin.com/in/mary-i-b1b24626b', 'https://www.linkedin.com/in/jaiminton', 'https://www.linkedin.com/in/alicia-omans-38767515', 'https://www.linkedin.com/in/sshreya', 'https://www.linkedin.com/in/allen-walker-61344b2ba', 'https://www.linkedin.com/in/matthew-stockwell', 'https://www.linkedin.com/in/sidmanchkanti', 'https://www.linkedin.com/in/f3d0r', 'https://www.linkedin.com/in/liezlpuzon', 'https://www.linkedin.com/in/adamzamri', 'https://www.linkedin.com/in/vijay-manohar-12820569', 'https://www.linkedin.com/in/edwardzhou96', 'https://www.linkedin.com/in/hamish-gunasekara', 'https://www.linkedin.com/in/rachel-l-19b220272', 'https://www.linkedin.com/in/vasumathi-raman', 'https://www.linkedin.com/in/bengbutler', 'https://www.linkedin.com/in/louis030195', 'https://www.linkedin.com/in/brandler', 'https://www.linkedin.com/in/billchen99', 'https://www.linkedin.com/in/harshgupta29', 'https://www.linkedin.com/in/chuan-melody-bi-78b161178', 'https://www.linkedin.com/in/hamutalm', 'https://www.linkedin.com/in/lucasparelius', 'https://www.linkedin.com/in/muruvig', 'https://www.linkedin.com/in/adamianrobertson', 'https://www.linkedin.com/in/kristian-yde-agerbo-1779355', 'https://www.linkedin.com/in/pete-davis-%E2%98%81', 'https://www.linkedin.com/in/frank-isaacson', 'https://www.linkedin.com/in/cameron-degelia', 'https://www.linkedin.com/in/lalore', 'https://www.linkedin.com/in/gkoshyk', 'https://www.linkedin.com/in/christopherllawson', 'https://www.linkedin.com/in/icorderi', 'https://www.linkedin.com/in/gal-malca', 'https://www.linkedin.com/in/adlr1', 'https://www.linkedin.com/in/carolinezhang12', 'https://www.linkedin.com/in/sinasojoodi', 'https://www.linkedin.com/in/weiye-zhao-45321a287', 'https://www.linkedin.com/in/nithinsonti', 'https://www.linkedin.com/in/ariwasch', 'https://www.linkedin.com/in/anirudhk', 'https://www.linkedin.com/in/zackamartin', 'https://www.linkedin.com/in/virajkulkarni22', 'https://www.linkedin.com/in/chongzhang-li', 'https://www.linkedin.com/in/jeffrey-wang08', 'https://www.linkedin.com/in/ezra-ellette', 'https://www.linkedin.com/in/aikaaldayarova', 'https://www.linkedin.com/in/cubic-w-33a12520', 'https://www.linkedin.com/in/wbwu', 'https://www.linkedin.com/in/oz-wasserman', 'https://www.linkedin.com/in/sumeet-sobti-a3726a4', 'https://www.linkedin.com/in/nnardelli', 'https://www.linkedin.com/in/yuxiaozhang19', 'https://www.linkedin.com/in/ji-kim222', 'https://www.linkedin.com/in/maebert', 'https://www.linkedin.com/in/ryanthardy', 'https://www.linkedin.com/in/samiragadri', 'https://www.linkedin.com/in/mgoodhearted', 'https://www.linkedin.com/in/rafi-benzaquen-26368013', 'https://www.linkedin.com/in/datastrategy', 'https://www.linkedin.com/in/tianshou', 'https://www.linkedin.com/in/joshuamanela', 'https://www.linkedin.com/in/changliu1991', 'https://www.linkedin.com/in/kashg', 'https://www.linkedin.com/in/qaissaria', 'https://www.linkedin.com/in/jianhonglu', 'https://www.linkedin.com/in/nikhilsimha', 'https://www.linkedin.com/in/antonia-creswell-579a8981', 'https://www.linkedin.com/in/dimitri-archatow-59935541', 'https://www.linkedin.com/in/cyrus-asfa-5a9521264', 'https://www.linkedin.com/in/aldo-siananta', 'https://www.linkedin.com/in/abram-burkholder-0b500394', 'https://www.linkedin.com/in/blake-wolfson', 'https://www.linkedin.com/in/guy-fridman-18172240', 'https://www.linkedin.com/in/delarre', 'https://www.linkedin.com/in/vibhor92', 'https://www.linkedin.com/in/josephma293', 'https://www.linkedin.com/in/jacobgianan', 'https://www.linkedin.com/in/mjahr', 'https://www.linkedin.com/in/meghanscanlon', 'https://www.linkedin.com/in/shilpatha-channappa', 'https://www.linkedin.com/in/devangsachdev', 'https://www.linkedin.com/in/alan-allen-b725332a6', 'https://www.linkedin.com/in/diogomda', 'https://www.linkedin.com/in/barryfoleysalesprofessional', 'https://www.linkedin.com/in/joennash', 'https://www.linkedin.com/in/bhowmickabhishek', 'https://www.linkedin.com/in/joshua-glover-544742111', 'https://www.linkedin.com/in/shin1111', 'https://www.linkedin.com/in/kyleneflechsig', 'https://www.linkedin.com/in/stephanie-song-768965129', 'https://www.linkedin.com/in/paul-lockett-544992bb', 'https://www.linkedin.com/in/john-hancock-jej', 'https://www.linkedin.com/in/chenjin0', 'https://www.linkedin.com/in/francisemccann', 'https://www.linkedin.com/in/jake-berdine-205b5843', 'https://www.linkedin.com/in/coryjsnyder', 'https://www.linkedin.com/in/aidarbek', 'https://www.linkedin.com/in/anoopmohandigitization', 'https://www.linkedin.com/in/smhaque', 'https://www.linkedin.com/in/mbutler01', 'https://www.linkedin.com/in/anthonyemberley', 'https://www.linkedin.com/in/justin-s-yu', 'https://www.linkedin.com/in/rory-buchanan-%F0%9F%91%B7-506b86166', 'https://www.linkedin.com/in/carlos-augusto-alves', 'https://www.linkedin.com/in/abhijitherekar', 'https://www.linkedin.com/in/kamal-a-3a8966115', 'https://www.linkedin.com/in/ingrid-l', 'https://www.linkedin.com/in/jnguyen-engr', 'https://www.linkedin.com/in/raj-k-5b005535', 'https://www.linkedin.com/in/tarstarr', 'https://www.linkedin.com/in/jamespurvis', 'https://www.linkedin.com/in/jenchalfan', 'https://www.linkedin.com/in/kuanghan', 'https://www.linkedin.com/in/jessevolk', 'https://www.linkedin.com/in/sebastian-meza-2594401b4', 'https://www.linkedin.com/in/dave-newman-b1964629', 'https://www.linkedin.com/in/michaelclange', 'https://www.linkedin.com/in/md-hasan-3z', 'https://www.linkedin.com/in/mirafiq', 'https://www.linkedin.com/in/chrischimenti', 'https://www.linkedin.com/in/jacobblish', 'https://www.linkedin.com/in/sameer-chauhan-35513578', 'https://www.linkedin.com/in/matt-bebb-21405662', 'https://www.linkedin.com/in/~iyer', 'https://www.linkedin.com/in/mayamonico', 'https://www.linkedin.com/in/michelleogorzal', 'https://www.linkedin.com/in/kevinkuchta', 'https://www.linkedin.com/in/christopher-spaulding-96a7882a', 'https://www.linkedin.com/in/shacka', 'https://www.linkedin.com/in/ajaysubramanian', 'https://www.linkedin.com/in/stevehorvath2022', 'https://www.linkedin.com/in/liuandy1', 'https://www.linkedin.com/in/miradu', 'https://www.linkedin.com/in/v-anais-o-ab21582b4', 'https://www.linkedin.com/in/-youngjae', 'https://www.linkedin.com/in/thiago-berlingieri-97336014', 'https://www.linkedin.com/in/ericvictorson', 'https://www.linkedin.com/in/bradleyemi', 'https://www.linkedin.com/in/dale-turner-', 'https://www.linkedin.com/in/n-h-nguyen', 'https://www.linkedin.com/in/ericjfeng']\n"
     ]
    }
   ],
   "source": [
    "print(to_scrape_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c8979-0304-4621-ae96-59108d44bada",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# deduplicate to_scrape_urls, declaring candidates and scraped_url lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea0fe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n"
     ]
    }
   ],
   "source": [
    "# deduplicate to_scrape_urls\n",
    "with open('db/to_scrape.pickle', 'wb') as f:\n",
    "    to_scrape_urls = list(set(to_scrape_urls))\n",
    "    with open('db/already_scraped.pickle', 'rb') as f2:\n",
    "        already_scraped_urls = pickle.load(f2)\n",
    "        to_scrape_urls = [url for url in to_scrape_urls if url not in already_scraped_urls]\n",
    "        pickle.dump(to_scrape_urls, f)\n",
    "        print(len(to_scrape_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92e50d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "scraped_urls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da7736-3078-4e03-8be6-967f48640cdc",
   "metadata": {},
   "source": [
    "# ACTUAL PROFILE SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7187f14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To-Scrape Urls: len:171\n",
      "At index: 0 - url: https://www.linkedin.com/in/datastrategy\n",
      "https://www.linkedin.com/in/datastrategy/details/experience\n",
      "Found 13 experience items\n",
      "title: : Instructor\n",
      "company: : Stanford Continuing Studies Â· Contract\n",
      "dates: : May 2024 to Present Â· 3 mos\n",
      "location: : Palo Alto, California, United States Â· On-site\n",
      "summary: : BUS 36 (https://bus36.org/) Instructor: teaching business leaders how to build and lead high-performance data analytics teams. The course will be held on beautiful Stanford campus and aims to help non-data professionals with domain knowledge (such as marketing, finance, operation, and product management) become successful leaders in data analytics. Data analytics refers to the process of examining data sets to draw conclusions and insights about the information they contain. I hope this course will be beneficial for all participants and create a strong community. ð¨ \"jeremygu@stanford.edu\": please send me emails about the course if you have questions!! https://continuingstudies.stanford.edu/courses/preview/20234_BUS-36/34C888F43046244D9564FFB78EDACA6C\n",
      "remaining: : BUS 36 Course Syllabus\n",
      "title: : Business Owner\n",
      "company: : Stealth Mode Â· Full-time\n",
      "dates: : May 2024 to Present Â· 3 mos\n",
      "location: : San Diego Metropolitan Area\n",
      "summary: : Hiring Tech (Math and CS) and Business/Marketing part-time roles and interns. Tech candidates must be pursuing undergrad or graduate degrees in Math, Stats, Computer Science, or EE/CSE majors. Marketing and other business candidates must be pursuing undergrad degrees in economics, marketing, or other business majors. Hybrid - location either San Diego, San Francisco, or Palo Alto. PM me for more details if you like to experience startup hype and work with smart talented people.\n",
      "title: : Adjunct Professor\n",
      "company: : University of San Francisco Â· Part-time\n",
      "dates: : Sep 2023 to Present Â· 11 mos\n",
      "location: : San Francisco, California, United States Â· On-site\n",
      "summary: : LinkedIn helped me get this job\n",
      "remaining: : Teaching graduate courses in data engineering (Kafka ecosystems, Airflow, FastAPI, ksqlDB, etc) MSDS 682 in the fall semester, 2023, 2024., Python (Programming Language) Â· Apache Kafka Â· Airflow Â· FastAPI, Syllabus MSDS 682 Stream Processing\n",
      "title: : Director of Data Science\n",
      "company: : Shipt Â· Full-time\n",
      "dates: : Sep 2021 to May 2024 Â· 2 yrs 9 mos\n",
      "location: : San Francisco, California, United States Â· On-site\n",
      "summary: : Head of Data Science, Fraud Detection and Risk Management (Acquired by Target) Jan 2023 - May 2024: We are building fraud detection capabilities for various fraud types such as transactional fraud, parcel theft, unauthorized access to driver accounts, and misuse of company credit cards, emphasizing the protection of assets for businesses and customers. Sep 2021 - Dec 2022: Managed teams developing geolocation capabilities (ETA, Mapping, etc.), market design tools (supply demand metrics and maps), analytical dashboards, forecasting models, and sophisticated experimentation tools (A/B testing, Switchback, Synthetic Control, Sequential tests). Pioneered the company's experimentation function, building the team and framework from scratch. As the first leader in this area, I spearhead the full spectrum of experimentation processes, including design, causal inference, metric development, hypothesis testing methodologies, and the creation of an open-source UI for sample size and power analysis, along with switchback tests.\n",
      "remaining: : Data Science Â· Python Â· Online Marketplace Â· Python (Programming Language) Â· Causal Inference Â· Statistics Â· Analytics Â· Data Governance Â· Optimization Â· Regulatory Requirements Â· Management Â· Risk Management Â· Network Optimization Â· Customer Acquisition Â· Geographic Information Systems (GIS) Â· Cybersecurity Â· California Consumer Privacy Act (CCPA) Â· General Data Protection Regulation (GDPR) Â· Snowflake Â· Flask, Using Causal Inference Model to Set Up Financial Goals of Company, User Manual: Sample Size Calculator for A/B Tests, Shipt Sample Size Calculator, Check out our sample size calculator tool (Public Version) that my team built! Please note that while this tool is publicly available, our other tools are only available within Shipt.\n",
      "title: : Manager of Data Science\n",
      "company: : Stitch Fix Â· Full-time\n",
      "dates: : Dec 2019 to Sep 2021 Â· 1 yr 10 mos\n",
      "location: : San Francisco Bay Area Â· On-site\n",
      "summary: : Head of Marketing Data Science and Channel Optimization. Directed A/B testing and performance marketing for all online and offline campaigns, focusing on ad optimization for customer acquisition. Spearheaded the pilot use of machine learning models for Facebook's Value Bidding (Value Optimization Product) and Google's Conversion Optimization Product, establishing new benchmarks in marketing efficiency and efficacy.\n",
      "remaining: : Data Science Â· Python Â· Online Marketplace Â· Python (Programming Language) Â· Statistics Â· Facebook Ads Â· Search Engine Marketing (SEM) Â· Digital Marketing Â· Management Â· Google BigQuery Â· New Product Rollout Â· Google Ads Â· Customer Acquisition Â· Search Engine Optimization (SEO) Â· California Consumer Privacy Act (CCPA) Â· General Data Protection Regulation (GDPR) Â· Personalization Â· Marketing Mix Modeling\n",
      "title: : Sr. Data Scientist and Manager, Experimentation Platform and Strategic Finance\n",
      "company: : Uber Â· Full-time\n",
      "dates: : Mar 2017 to Dec 2019 Â· 2 yrs 10 mos\n",
      "location: : San Francisco, California Â· On-site\n",
      "summary: : Mar 2017 - Sep 2018 (Promoted to Senior Data Scientist in 8/1/2018): Developed an experimentation platform focusing on A/B testing, enhancing reporting features (confidence interval, p-value calculations) on our Mentana Metrics Dashboard. Constructed a multi-armed bandit system for marketing automation, significantly contributing to Uber Eats campaigns in over 17 European countries, acquiring over 3 million paid users. Oct 2018 - Dec 2019 (Promoted to Data Science Manager in 1/14/2019): Played a key role in the IPO process, providing critical data support including data quality assurance, defining accounting rules, and conducting causal analysis of costs and losses. Led pilot launches and financial analyses of various initiatives, market balance assessment, and developed LTV forecasting models, underpinning strategic business decisions.\n",
      "remaining: : Data Science Â· Python Â· Online Marketplace Â· Python (Programming Language) Â· Causal Inference Â· Analytics Â· Data Governance Â· Management Â· Risk Management Â· New Product Rollout Â· SQL Â· Customer Acquisition Â· Geographic Information Systems (GIS) Â· Cybersecurity Â· California Consumer Privacy Act (CCPA) Â· General Data Protection Regulation (GDPR) Â· Personalization Â· R (Programming Language) Â· Marketing Mix Modeling Â· Design of Experiments (DOE)\n",
      "title: : Elected officer\n",
      "company: : American Statistical Association - ASA Â· Part-time\n",
      "dates: : Aug 2015 to Aug 2018 Â· 3 yrs 1 mo\n",
      "location: : San Francisco Bay Area\n",
      "summary: : Three terms (2015-16, 2016-17, 2017-18)\n",
      "remaining: : Management, Panel Discussion on Data Science Career Development, San Francisco Bay Area Chapter Hosts Career Development Panel\n",
      "title: : Applied Scientist\n",
      "company: : Amazon Â· Full-time\n",
      "dates: : Dec 2014 to Feb 2017 Â· 2 yrs 3 mos\n",
      "location: : Greater Seattle Area Â· On-site\n",
      "summary: : Dec 2014 - Mar 2017 at Amazon: Engaged in extensive AWS applications for developing advanced marketing machine learning models. This included building beta-binomial multi-armed bandits and conducting comprehensive A/B analyses. Additionally, I initiated and conducted A/B test office hours for marketing teams, fostering a culture of data-driven decision-making and enhancing the effectiveness of marketing strategies through tailored models such as forecasting new AWS user sign-ups, cross-selling algorithms, marketing spend analysis, and causal analysis of ROI from local events. Pioneered personalized ad campaigns for Facebook and bespoke product recommendations based on AWS browsing history, significantly boosting customer engagement and sales conversions.\n",
      "remaining: : Data Science Â· Databases Â· Python Â· Online Marketplace Â· Python (Programming Language) Â· Facebook Ads Â· Search Engine Marketing (SEM) Â· Digital Marketing Â· Data Governance Â· Amazon Redshift Â· New Product Rollout Â· Amazon Web Services (AWS) Â· Sales Operations Â· AWS Â· SQL Â· Google Ads Â· Customer Acquisition Â· Scala Â· Geographic Information Systems (GIS) Â· Search Engine Optimization (SEO) Â· Cybersecurity Â· Apache Spark Â· Business Intelligence (BI) Â· General Data Protection Regulation (GDPR) Â· Data Analysis Â· Personalization Â· R (Programming Language)\n",
      "title: : Data Modeler Intern, Sales Operations\n",
      "company: : F5 Networks Â· Internship\n",
      "dates: : Jun 2014 to Nov 2014 Â· 6 mos\n",
      "location: : Greater Seattle Area Â· On-site\n",
      "summary: : Data Science Â· Analytics Â· Statistical Modeling Â· Sales Operations Â· SQL Â· Planning Budgeting & Forecasting Â· Business Intelligence (BI) Â· Data Analysis Â· R (Programming Language)\n",
      "title: : Research Assistant\n",
      "company: : University of Washington Â· Part-time\n",
      "dates: : Dec 2013 to Jun 2014 Â· 7 mos\n",
      "location: : Greater Seattle Area\n",
      "summary: : Python (Programming Language) Â· Statistics Â· Data Analysis\n",
      "remaining: : Mixture Models for Estimating Maximum Blood Flow Velocity, \n",
      "title: : Statistical Specialist Intern\n",
      "company: : Big Water Consulting Â· Internship\n",
      "dates: : 2013 to 2013 Â· Less than a year\n",
      "location: : Greater Seattle Area\n",
      "summary: : Data Analysis Â· Geographic Information Systems (GIS)\n",
      "title: : Research Assistant\n",
      "company: : Carlson School of Management Â· Part-time\n",
      "dates: : Dec 2011 to Jan 2012 Â· 2 mos\n",
      "location: : Minneapolis Â· On-site\n",
      "summary: : Research project: Public data to determine leadership skills.\n",
      "title: : Research Intern, Mathematics Modeling Dept.\n",
      "company: : Schlumberger Â· Internship\n",
      "dates: : May 2011 to Aug 2011 Â· 4 mos\n",
      "location: : Greater Boston Area Â· On-site\n",
      "summary: : Machine Learning Â· Optimization Â· Statistical Modeling Â· MATLAB\n",
      "Successfully scraped experiences\n",
      "school: : University of Washington\n",
      "degree: : Master of Science - MS, Statistics\n",
      "dates: : 2014\n",
      "remaining: : \n",
      "school: : Harvard Business School\n",
      "degree: : Executive Program Certificate, Big Data 2018\n",
      "school: : Harvard Business School Executive Education\n",
      "degree: : Certificates - Management and Leadership\n",
      "dates: : 2017 - 2018\n",
      "remaining: : \n",
      "school: : University of Minnesota\n",
      "degree: : Magna Honors, Bachelor of Science (BS), Mathematics and Statistics (double major)\n",
      "dates: : 2012\n",
      "remaining: : Statistics\n",
      "successfully scraped education\n",
      "successfully scraped degree of connection\n",
      "successfully scraped description\n",
      "successfully scraped profile link\n",
      "<__main__.ScrapedProfile object at 0x11053eb20>\n",
      "saving profile info; recording scraped url; removing from to-scrape; success!\n",
      "0.5847953216374269 % Done - at index: 0\n",
      "At index: 1 - url: https://www.linkedin.com/in/ying-zhu-763a3879\n",
      "https://www.linkedin.com/in/ying-zhu-763a3879/details/experience\n",
      "Found 4 experience items\n",
      "title: : Co-Founder\n",
      "company: : Stealth AI Startup\n",
      "dates: : Mar 2024 to Present Â· 5 mos\n",
      "title: : Airbnb\n",
      "company: : 5 yrs 11 mos\n",
      "dates: : Senior Software Engineer\n",
      "location: : Full-time\n",
      "summary: : Sep 2021 to Mar 2024 Â· 2 yrs 7 mos\n",
      "remaining: : United States, Service Mesh Team: Building the next generation Service Mesh based on Istio at Airbnb. My work includes: mesh API, observability, TCP and external service support, egress gateway, mesh scalability and performance, etc. I am also an active Istio member and love to contribute back to the open source community. Check out:, Blog Post - Improving Istio Propagation Delay, IstioCon Talk - Building simplified service mesh API for developers, Software Engineer, May 2018 to Sep 2021 Â· 3 yrs 5 mos, San Francisco Bay Area, 2019 - 2021: Service Mesh Team 2018 - 2019: Customer Service for Airbnb China Built an emergency support feature for helping people contact local police within the Airbnb app. Built the help center within Airbnb Wechat miniapp. Built a filtering service for scraping out PII data for compliance requirements.\n",
      "title: : Software Engineer Intern\n",
      "company: : Airbnb\n",
      "dates: : May 2017 to Aug 2017 Â· 4 mos\n",
      "location: : San Francisco Bay Area\n",
      "summary: : Growth Team\n",
      "title: : Software Engineer Intern\n",
      "company: : Roxar\n",
      "dates: : Jul 2015 to Sep 2015 Â· 3 mos\n",
      "location: : Oxford, United Kingdom\n",
      "Successfully scraped experiences\n",
      "school: : Columbia University\n",
      "degree: : Master of Science (M.Sc.), Computer Science\n",
      "dates: : 2016 - 2017\n",
      "school: : University of Oxford\n",
      "degree: : Bachelor of Arts (BA), Mathematics and Computer Science\n",
      "dates: : 2013 - 2016\n",
      "remaining: : \n",
      "successfully scraped education\n",
      "successfully scraped degree of connection\n",
      "successfully scraped description\n",
      "successfully scraped profile link\n",
      "<__main__.ScrapedProfile object at 0x107a8bee0>\n",
      "saving profile info; recording scraped url; removing from to-scrape; success!\n",
      "1.1695906432748537 % Done - at index: 1\n",
      "At index: 2 - url: https://www.linkedin.com/in/ericjfeng\n",
      "https://www.linkedin.com/in/ericjfeng/details/experience\n",
      "Found 6 experience items\n",
      "title: : John Avenue\n",
      "company: : 1 yr 3 mos\n",
      "dates: : SPintern\n",
      "location: : Jun 2024 to Present Â· 2 mos\n",
      "summary: : Hong Kong, Hong Kong SAR\n",
      "remaining: : - SPinning, Incoming SPecialist, Aug 2023 to Present Â· 1 yr, SPintern, May 2023 to Aug 2023 Â· 4 mos, Manhattan, New York, United States, - SPun\n",
      "title: : Associate Product Manager Intern\n",
      "company: : Hudl\n",
      "dates: : May 2022 to May 2023 Â· 1 yr 1 mo\n",
      "location: : - Beta testing and livestreaming implementation for Focus Flex, our newest AI-powered sports camera\n",
      "title: : Product Manager\n",
      "company: : Yoomi\n",
      "dates: : Nov 2022 to Jan 2023 Â· 3 mos\n",
      "location: : - First product manager for Yoomi, a startup using gamification and ML to make physical therapy more fun and effective\n",
      "title: : Founder\n",
      "company: : Stealth Startup\n",
      "dates: : Sep 2022 to Jan 2023 Â· 5 mos\n",
      "location: : Nashville, Tennessee, United States\n",
      "summary: : - Seeking to revolutionize trips and social connections - Sullivan Family Ideator Fellow @ The Wond'ry (Vanderbilt Innovation Center)\n",
      "title: : Research Assistant\n",
      "company: : Lillehei Heart Institute\n",
      "dates: : Jun 2019 to Aug 2021 Â· 2 yrs 3 mos\n",
      "location: : Jop van Berlo Laboratory\n",
      "summary: : - Image analysis algorithm development and wet lab work to investigate cardiomyocyte (heart muscle cell) maturation - Won $3000 grant as a 2021 Lillehei Summer Research Scholar\n",
      "title: : Strategy Consulting Competition Winner\n",
      "company: : DoorDash\n",
      "dates: : Sep 2020 to Nov 2020 Â· 3 mos\n",
      "location: : - User segmentation and go-to-market strategy for DoorDash in college markets - Placed 1st in the IACBE Fall 2020 Virtual Live Case Competition, hosted by DoorDash\n",
      "Successfully scraped experiences\n",
      "school: : Vanderbilt University\n",
      "degree: : Bachelor of Science - BS, Computer Science\n",
      "dates: : Activities and societies: Product Space, Change++, Theta Tau, Club Table Tennis\n",
      "school: : Mounds View Senior High School\n",
      "degree: : High School Diploma\n",
      "school: : Universidad Carlos III de Madrid\n",
      "degree: : Study Abroad\n",
      "successfully scraped education\n",
      "successfully scraped degree of connection\n",
      "successfully scraped description\n",
      "successfully scraped profile link\n",
      "<__main__.ScrapedProfile object at 0x107de55e0>\n",
      "saving profile info; recording scraped url; removing from to-scrape; success!\n",
      "1.7543859649122806 % Done - at index: 2\n",
      "At index: 3 - url: https://www.linkedin.com/in/yazwashere\n",
      "https://www.linkedin.com/in/yazwashere/details/experience\n",
      "Found 6 experience items\n",
      "title: : Chief Executive Officer\n",
      "company: : Starting something new Â· Full-time\n",
      "dates: : Jan 2024 to Present Â· 7 mos\n",
      "location: : New York, New York, United States\n",
      "title: : Senior Machine Learning Engineer\n",
      "company: : Meta Â· Full-time\n",
      "dates: : Sep 2022 to May 2024 Â· 1 yr 9 mos\n",
      "title: : Software Engineer\n",
      "company: : Wing\n",
      "dates: : Jul 2020 to Jul 2022 Â· 2 yrs 1 mo\n",
      "title: : Software Engineer\n",
      "company: : Uber ATG\n",
      "dates: : Jul 2018 to Jul 2020 Â· 2 yrs 1 mo\n",
      "title: : Software Engineer\n",
      "company: : Amazon Web Services (AWS)\n",
      "dates: : Jun 2017 to Dec 2017 Â· 7 mos\n",
      "location: : Greater Seattle Area\n",
      "title: : Software Engineer\n",
      "company: : LLamasoft, Inc.\n",
      "dates: : Jun 2015 to Jun 2017 Â· 2 yrs 1 mo\n",
      "location: : Ann Arbor, MI\n",
      "Successfully scraped experiences\n",
      "school: : University of Michigan\n",
      "degree: : Bachelor's of Science, Computer Science\n",
      "dates: : 2010 - 2015\n",
      "successfully scraped education\n",
      "successfully scraped degree of connection\n",
      "successfully scraped description\n",
      "successfully scraped profile link\n",
      "<__main__.ScrapedProfile object at 0x11053e340>\n",
      "saving profile info; recording scraped url; removing from to-scrape; success!\n",
      "2.3391812865497075 % Done - at index: 3\n",
      "At index: 4 - url: https://www.linkedin.com/in/pennypinyichen\n",
      "https://www.linkedin.com/in/pennypinyichen/details/experience\n",
      "Found 6 experience items\n",
      "title: : Co-Founder and CEO\n",
      "company: : Stealth Â· Full-time\n",
      "dates: : Jun 2024 to Present Â· 2 mos\n",
      "location: : San Francisco Bay Area\n",
      "title: : Research Scientist\n",
      "company: : Amazon Â· Full-time\n",
      "dates: : Jan 2024 to Jun 2024 Â· 6 mos\n",
      "location: : Seattle, Washington, United States\n",
      "summary: : Allocation algorithms for device inventories\n",
      "title: : Applied Research Scientist\n",
      "company: : Flexport Â· Full-time\n",
      "dates: : Nov 2022 to Oct 2023 Â· 1 yr\n",
      "location: : Pricing algorithms for air freights\n",
      "title: : Research Scientist Intern\n",
      "company: : Amazon Â· Internship\n",
      "dates: : Jul 2021 to Sep 2021 Â· 3 mos\n",
      "location: : Seattle, Washington, United States\n",
      "summary: : Order fulfillment algorithms for middle-mile logistics\n",
      "title: : Research Scientist Intern\n",
      "company: : Amazon Â· Internship\n",
      "dates: : Jul 2020 to Sep 2020 Â· 3 mos\n",
      "title: : Research Scientist Intern\n",
      "company: : Amazon Â· Internship\n",
      "dates: : Jun 2019 to Aug 2019 Â· 3 mos\n",
      "Successfully scraped experiences\n",
      "school: : Y Combinator\n",
      "degree: : 2024 - 2024\n",
      "dates: : S24\n",
      "school: : Massachusetts Institute of Technology\n",
      "degree: : Doctor of Philosophy - PhD\n",
      "dates: : 2016 - Jun 2022\n",
      "school: : Massachusetts Institute of Technology\n",
      "degree: : Dual Master's Degree in MechE and EECS\n",
      "dates: : 2016 - 2020\n",
      "school: : National Taiwan University\n",
      "degree: : Bachelor's degree, Mechanical Engineering\n",
      "dates: : 2012 - 2016\n",
      "successfully scraped education\n",
      "successfully scraped degree of connection\n",
      "successfully scraped description\n",
      "successfully scraped profile link\n",
      "<__main__.ScrapedProfile object at 0x107a8b610>\n",
      "saving profile info; recording scraped url; removing from to-scrape; success!\n",
      "2.923976608187134 % Done - at index: 4\n",
      "At index: 5 - url: https://www.linkedin.com/in/kamal-a-3a8966115\n",
      "https://www.linkedin.com/in/kamal-a-3a8966115/details/experience\n",
      "Found 7 experience items\n",
      "title: : Global Enterprise GTM\n",
      "company: : Oracle Â· Full-time\n",
      "dates: : 2024 to Present Â· 7 mos\n",
      "location: : Remote\n",
      "summary: : Supporting global enterprise companies with strategic Oracle investments, specializing in complex cloud transformations across ERP, EPM, CX, SCM, and HCM\n",
      "title: : Enterprise Account Executive\n",
      "company: : Motive Â· Full-time\n",
      "dates: : 2023 to 2024 Â· 1 yr\n",
      "location: : Leading strategic sales engagements with Fortune 1000 companies and public sectors,\n",
      "summary: : Palantir Â· New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales\n",
      "title: : DocuSign\n",
      "company: : Full-time Â· 1 yr 8 mos\n",
      "dates: : RVP Sales Higher Education\n",
      "location: : Jan 2023 to May 2023 Â· 5 mos\n",
      "summary: : Remote\n",
      "remaining: : Palantir Â· New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales, ENT Account Executive, Higher Education, Oct 2021 to Dec 2022 Â· 1 yr 3 mos, Palantir Â· New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales\n",
      "title: : Co-founder CEO\n",
      "company: : Stealth Startup Â· Full-time\n",
      "dates: : Sep 2021 to Dec 2021 Â· 4 mos\n",
      "location: : Founded a fintech startup, achieving approximately $15 million in transaction volume over a three-year period in the logistics sector. â¢ Exhibited exceptional leadership, collaborating with cross-functional teams to drive business growth.\n",
      "summary: : Palantir Â· New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales\n",
      "title: : Samsara\n",
      "company: : Full-time Â· 2 yrs 11 mos\n",
      "dates: : Atlanta, Georgia, United States\n",
      "location: : Strategic sales (Go-to-market Canada)\n",
      "summary: : Jul 2020 to Oct 2021 Â· 1 yr 4 mos\n",
      "remaining: : I joined Samsara as the second AE to expand to the Canadian market. I helped the initiative by building relationships with reseller partners in Canada and identifying new revenue opportunities in the market. In three years, we drove sales revenue from zero to $30 Million+ in ARR and received multiple awards. I helped logistics & trucking businesses contain costs on their fleets through the use of SaaS fleet management software and IoT sensors for compliance safety and logistics operations. Awards & Key Accomplishments -FY22 Q2: Top 2 rep -FY22 Q1: Top 3 rep -FY21 Winnerâs Circle (Top 5%) -FY21 Q4: MVP of the Quarter Directorâs Award Top Performer -FY21 Q2: MVP of the Quater Directorâs Award Top Performer. -FY20 Winnerâs Circle and Top International Rep (Top 5%) -FY20 Q4: MVP of the Quarter. Top Performer/ Director Award -FY20 Q2: MVP of the Quarter Quota Attainment FY22 Q1: 176% to goal FY21 Q4: 310% to goal FY21 Q3: 150% to goal FY21 Q2: 250% to goal FY21 Q1: 100% to goal FY20 Q4: 370% to goal FY20 Q3: 55% to goal FY20 Q2: 400% to goal, Palantir Â· New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales, Senior Account Executive, Dec 2018 to Jun 2020 Â· 1 yr 7 mos, Awards & Key Accomplishments -FY22 Q2: Top 2 rep -FY22 Q1: Top 3 rep -FY21 Winnerâs Circle (Top 5%) -FY21 Q4: MVP of the Quarter Directorâs Award Top Performer -FY21 Q2: MVP of the Quater Directorâs Award Top Performer. -FY20 Winnerâs Circle and Top International Rep (Top 5%) -FY20 Q4: MVP of the Quarter. Top Performer/ Director Award -FY20 Q2: MVP of the Quarter, Palantir Â· New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales\n",
      "title: : Verizon Connect\n",
      "company: : Full-time Â· 3 yrs 9 mos\n",
      "dates: : Enterprise Account Executive\n",
      "location: : Feb 2017 to Jan 2018 Â· 1 yr\n",
      "summary: : I strive to help Enterprise-sized trucking & other businesses contain cost on their fleets through the use of our SaaS GPS software. Verizon Connect fleet tracking software is used by more than 42,000 Customers, tracking over 826,000 Fleet Vehicles, and has collected over 115 Billion Data Points. â¢ 2017 Presidents Club/Top Performer\n",
      "remaining: : Palantir Â· New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales, Senior Account Executive, May 2014 to Feb 2017 Â· 2 yrs 10 mos, I was responsible for selling the Verizon Connect portfolio to mid-sized clients. Key Accomplishments: â¢ Achieved Winners Circle in 2015 for top National sales performance at Verizon â¢ Achieved Presidents Club in 2016 for top National sales performance at Verizon â¢ 2016 Presidents Club/Top Performer â¢ Average 250% of quota, Palantir Â· New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales\n",
      "title: : Commercial Strategy Specialist - International Revenue\n",
      "company: : Delta Air Lines Â· Full-time\n",
      "dates: : Feb 2012 to Jun 2013 Â· 1 yr 5 mos\n",
      "location: : Pricing Strategy | Domestic | West Region Maximize revenue and profitability by planning and developing pricing strategies while maintaining and growing market share.\n",
      "summary: : New Leads Â· Value Creation Â· New Business Opportunities Â· Outbound Sales\n",
      "Successfully scraped experiences\n",
      "education not found\n",
      "successfully scraped education\n",
      "successfully scraped degree of connection\n",
      "successfully scraped description\n",
      "successfully scraped profile link\n",
      "local variable 'education' referenced before assignment\n",
      "Failed to scrape profile:  https://www.linkedin.com/in/kamal-a-3a8966115\n",
      "At index: 6 - url: https://www.linkedin.com/in/shacka\n",
      "https://www.linkedin.com/in/shacka/details/experience\n",
      "Found 13 experience items\n",
      "title: : Staff Software Engineer\n",
      "company: : Freed Â· Full-time\n",
      "dates: : Mar 2024 to Present Â· 5 mos\n",
      "title: : Staff Software Engineer\n",
      "company: : LULA Â· Full-time\n",
      "dates: : Dec 2022 to Dec 2023 Â· 1 yr 1 mo\n",
      "title: : Staff Software Engineer\n",
      "company: : Tempo Â· Full-time\n",
      "dates: : Nov 2020 to Nov 2022 Â· 2 yrs 1 mo\n",
      "title: : Staff Software Engineer\n",
      "company: : DoorDash Â· Full-time\n",
      "dates: : Oct 2019 to Nov 2020 Â· 1 yr 2 mos\n",
      "location: : San Francisco, California, United States\n",
      "title: : Lead Software Engineer\n",
      "company: : ALICE Technologies Inc.\n",
      "dates: : Oct 2017 to Oct 2019 Â· 2 yrs 1 mo\n",
      "location: : San Francisco Bay Area\n",
      "summary: : Lead software engineer\n",
      "title: : Sr. Site Reliability Engineer\n",
      "company: : LinkedIn\n",
      "dates: : Dec 2015 to Mar 2017 Â· 1 yr 4 mos\n",
      "location: : SF Bay Area\n",
      "title: : Staff Engineer\n",
      "company: : Virtual Instruments\n",
      "dates: : Oct 2013 to Oct 2015 Â· 2 yrs 1 mo\n",
      "location: : San Jose, CA\n",
      "title: : Member of Technical Staff\n",
      "company: : VMware\n",
      "dates: : Nov 2011 to Oct 2013 Â· 2 yrs\n",
      "location: : Palo Alto, CA\n",
      "title: : Senior Software Engineer\n",
      "company: : EPAM Systems\n",
      "dates: : Dec 2010 to Oct 2011 Â· 11 mos\n",
      "location: : Contractor at YouTube.\n",
      "title: : Software Engineer\n",
      "company: : Scionics Computer Innovation GmbH\n",
      "dates: : May 2009 to Nov 2010 Â· 1 yr 7 mos\n",
      "location: : Dresden Area, Germany\n",
      "title: : Software Engineer\n",
      "company: : MyDeco.com\n",
      "dates: : Jul 2007 to Feb 2009 Â· 1 yr 8 mos\n",
      "location: : Kyiv, Ukraine\n",
      "summary: : Working on new generation web 2.0 portal based on Django as a lead of agile team.\n",
      "title: : System Administrator\n",
      "company: : Zapatec Inc\n",
      "dates: : Mar 2006 to Jun 2007 Â· 1 yr 4 mos\n",
      "title: : Web developer\n",
      "company: : We&Cat SG (now - Frontier Web Development)\n",
      "dates: : Jan 2002 to Mar 2006 Â· 4 yrs 3 mos\n",
      "Successfully scraped experiences\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# scrape profiles, and write results to a file\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m   profile \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_profile_live_filtering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m profile \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaving profile info\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 156\u001b[0m, in \u001b[0;36mscrape_profile_live_filtering\u001b[0;34m(driver, profile_link)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     education_url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(profile_link, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetails/education\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43meducation_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m    159\u001b[0m     education_items \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli.pvs-list__paged-list-item.artdeco-list__item.pvs-list__item--line-separated.pvs-list__item--one-column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/remote/webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/remote/webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# iterates through to_scrape_urls, scrapes and adds to list: candidates\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "with open('db/to_scrape.pickle', 'rb') as f:\n",
    "    to_scrape_urls = pickle.load(f)\n",
    "\n",
    "print(f'To-Scrape Urls: len:{len(to_scrape_urls)}')\n",
    "\n",
    "start = 0\n",
    "end = len(to_scrape_urls)\n",
    "\n",
    "for idx, url in enumerate(to_scrape_urls.copy()):\n",
    "  if start > idx:\n",
    "    continue\n",
    "  if idx >= end:\n",
    "    break\n",
    "  print(f'At index: {idx} - url: {url}') \n",
    "  \n",
    "  # scrape profiles, and write results to a file\n",
    "  try:\n",
    "    profile = scrape_profile_live_filtering(driver, url)\n",
    "    \n",
    "    if profile != None:\n",
    "        print(\"saving profile info\", end=\"\")\n",
    "        candidates.append(profile)\n",
    "\n",
    "        print(\"; recording scraped url\", end=\"\")\n",
    "        url = url.strip().strip('/')\n",
    "        scraped_urls.append(url)\n",
    "    else:\n",
    "        print(\"profile filtered out\", end=\"\")\n",
    "    \n",
    "    print(\"; removing from to-scrape\", end=\"\")\n",
    "    to_scrape_urls.remove(url)\n",
    "    with open('db/to_scrape.pickle', 'wb') as f:\n",
    "      pickle.dump(to_scrape_urls, f)\n",
    "\n",
    "    print(\"; success!\")\n",
    "    print(((idx+1)/end) * 100, '% Done - at index:', idx)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    print('Failed to scrape profile: ', url)\n",
    "    with open('failed_urls.txt', 'a') as f:\n",
    "      f.write(url + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47185763-6f2b-4f89-9acc-1651887008f6",
   "metadata": {},
   "source": [
    "# rest of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in candidates:\n",
    "    e = x.experiences[0]\n",
    "    print(e.to_date, e.position_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd44fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=[\"url\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0906d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCandidate(x):\n",
    "    res = {}\n",
    "    res['url'] = x.profile_link\n",
    "    res['name'] = x.profile_name\n",
    "    res['dist'] = x.profile_dist\n",
    "    res['description'] = x.profile_description\n",
    "    schoolIndex = 0\n",
    "    for i, e in enumerate(x.profile_school):\n",
    "        res[f'edu{i} school'] = e[\"school\"]\n",
    "        res[f'edu{i} degree'] = e[\"degree\"]\n",
    "        schoolIndex += 1\n",
    "    exp = 0\n",
    "    for i, e in enumerate(x.experiences):\n",
    "        res[f'exp{i} title'] = e.position_title\n",
    "        res[f'exp{i} company'] = e.institution_name.split(\" Â·\")[0]\n",
    "        res[f'exp{i} duration'] = e.duration\n",
    "        res[f'exp{i} start'] = e.from_date\n",
    "        exp += 1\n",
    "    return res\n",
    "\n",
    "for candidate in candidates:\n",
    "    row = parseCandidate(candidate)\n",
    "    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# update db/already_scraped.pickle\n",
    "with open('db/already_scraped.pickle', 'rb') as f:\n",
    "    already_scraped = pickle.load(f)\n",
    "    print(f\"Previously scraped: {len(already_scraped)}\")\n",
    "    already_scraped = already_scraped + scraped_urls\n",
    "    already_scraped = list(set(already_scraped))\n",
    "    print(f\"Newly scraped: {len(already_scraped)}\")\n",
    "with open('db/already_scraped.pickle', 'wb') as f:\n",
    "    pickle.dump(already_scraped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee20a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = COMPANY_CATEGORIES\n",
    "\n",
    "# Example color mapping for categories\n",
    "category_colors = {\n",
    "    \"SECURITY\": 'red',\n",
    "    \"OTHER\": 'blue',\n",
    "    \"PUBLIC\": 'green',\n",
    "    \"INFRA\": 'yellow',\n",
    "    \"FINTECH\": 'orange',\n",
    "    \"CRYPTO\": 'purple',\n",
    "    \"FRONTIER\": 'cyan',\n",
    "    \"AI\": 'magenta'\n",
    "}\n",
    "\n",
    "# Create a reverse dictionary for easier lookup: {company: category}\n",
    "company_category = {}\n",
    "for category, companies in categories.items():\n",
    "    for company in companies:\n",
    "        company_category[company] = category\n",
    "\n",
    "# Modify the style function\n",
    "def highlight_by_category(val):\n",
    "    category = company_category.get(val)\n",
    "    if category:\n",
    "        color = category_colors.get(category, 'none')  # default to 'none' if no color is specified\n",
    "    else:\n",
    "        color = 'none'\n",
    "    return f'background-color: {color}'\n",
    "\n",
    "import re\n",
    "ILLEGAL_CHARACTERS_RE = re.compile(r'[\\000-\\010]|[\\013-\\014]|[\\016-\\037]')\n",
    "def find_illegal_characters(df):\n",
    "    for column in df.columns:\n",
    "        for idx, item in enumerate(df[column]):\n",
    "            if isinstance(item, str) and ILLEGAL_CHARACTERS_RE.search(item):\n",
    "                # replace illegal characters with an empty string\n",
    "                df[column][idx] = ILLEGAL_CHARACTERS_RE.sub('', item)\n",
    "    return df\n",
    "\n",
    "styled_df = df\n",
    "styled_df = find_illegal_characters(styled_df)\n",
    "styled_df = df.style.applymap(highlight_by_category)\n",
    "\n",
    "# Save the styled DataFrame to an Excel file\n",
    "# get today's date in MM-DD-YYYY format\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%m-%d-%Y\")\n",
    "styled_df.to_excel(f'results/{date}_{start}-{end}.xlsx', engine='openpyxl', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
